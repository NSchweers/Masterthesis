\documentclass[a4paper,10pt,twoside]{article}
%\documentclass[b5paper,8pt,twoside]{article}
%\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage{cite}
\tolerance=1000
\usepackage{minted}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{tikz}

\usetikzlibrary{trees}
%\tikzstyle op=[draw, circle]
%\tikzstyle arg=[]
\tikzstyle op=[inner sep=0,draw,circle,minimum size=0.8cm,execute at begin node=$,execute at end node=$]
\tikzstyle arg=[minimum size=.6cm,inner sep=0,draw,circle,fill=gray!50!white]



\author{Nathanael Schweers}
\date{\today}
\title{Proof of Concept: An implementation of a reader for extensible syntaxes for Emacs Lisp}
% \hypersetup{
%   pdfkeywords={},
%   pdfsubject={},
%   pdfcreator={Emacs 25.0.91.1 (Org mode 8.2.10)}}

\newcommand{\el}{Emacs Lisp}
\newcommand{\cl}{Common Lisp}
\newcommand{\elr}{el-reader}
\newcommand{\sym}[1]{\texttt{#1}}
\newcommand{\fun}[1]{\texttt{#1}}
\newcommand{\emacs}{GNU Emacs}
\newcommand{\unix}{\textsc{unix}}

\newenvironment{myEnv} [2]
{\begin{frame} \frametitle{#1} \framesubtitle{#2} \begin{center}}
{\end{center} \end{frame}}

\newenvironment{sourcecode} [2]
{\begin{listing}[h] \label{#1} \caption{#2} \begin{verbatim}}
{\end{verbatim} \end{listing}}

%\newminted{cl}{}

\lstset{         %
  language=Lisp, %
  frame=single,  %
  float,         %
  captionpos=b}

\lstdefinestyle{lispcode}{
  language=Lisp,
  basicstyle=\small,
  frame=single,
  float,
  captionpos=b,
  %stringstyle=\color{red},
  %keywordstyle=\bfseries\color{purple}
  showstringspaces=false
}

\lstdefinestyle{lispinline}{
  language=Lisp, 
  showstringspaces=false}

\lstdefinestyle{pythoncode}{
  language=python,
  basicstyle=\small,
  showstringspaces=false
}

\lstdefinestyle{rubycode}{
  language=ruby,
  basicstyle=\small,
  float,
  captionpos=b,
  showstringspaces=false
}

\lstdefinestyle{rubyinline}{
  language=ruby,
  basicstyle=\small,
  showstringspaces=false
}

\begin{document}

\maketitle
\tableofcontents

\begin{abstract}
  This thesis discusses the design and implementation of a proof of concept for
  an \el{} compatible reader for extensible syntaxes, in \el{}, named
  ``\elr{}''.  In Lisp parlance, the reader is the part of the
  interpreter/compiler, which converts the characters in the source code to data
  structures, which are then further processed.  In an extensible reader, new
  syntactic constructs may be defined.  These new constructs take effect when
  specific characters are encountered in the source code, and may interact with
  the existing reader to create arbitrary data structures which are later either
  interpreted or compiled by the Lisp environment.

  Some other languages feature such capabilities, of which \cl{} is most widely
  known.  Some Scheme implementations also provide these or similar
  possibilities, yet this is not part of the standard.  SRFI-10 provides a
  specific character sequence with which all read macros must
  start. \cite{srfi-10}

  In \cl{} the possibility to interact with the reader is called a read macro or
  reader macro, and this term will also be used throughout this thesis.

  \el{} does not provide reader macros.  As of the upcoming version 25.1 the
  reader is implemented in C and does not provide any hooks into it, apart from
  the usual advice system, which all \el{} functions provide.

  The code underlying this thesis provides a means to replace the reader built
  into Emacs.  The main point of this thesis is to show that the flexible nature
  of a Lisp environment may be used to replace even such a crucial part of the
  system as the reader at runtime, without affecting unrelated parts, or making
  the original part unavailable.
\end{abstract}

\section{A brief history of Lisp}
\label{sec:lisp-hist}

Pinpointing Lisps exact moment of birth is rather difficult, as it is often the
case with Ideas which take some time to develop.  John McCarthy published a
paper in 1960 on the language\cite{rec-fun-sym-expr} in which some ideas,
notation among others, from Alonzo Church’s $\lambda$-calculus are used.

The gist of the paper is that McCarthy devised a theoretic system to represent
functions in programs.  This was originally meant as a theoretic foundation,
yet, as McCarthy writes in his retrospective notes on Lisp history
\cite{lisp-hist}: “S.R. Russell noticed that eval could serve as an interpreter
for LISP, promptly hand coded it, and we now had a programming language with an
interpreter.”

While it may have been an accident that Lisp got an implementation, thus
becoming an actual programming language at the time that it did, the foundation
was laid down at that time, so it could have happened at any later point.

As Lisp introduced several ideas which were new to programming, resulting in
high expressive power, it quickly became popular in some circles, especially the
artificial intelligence community, of which McCarthy war a part.  This was
probably simply because Lisp was more powerful than any other language of the
time, even though it was very slow.  Paul Graham nicely listed 9 particularly
important ideas: \cite{pg-lisp-diff}

\begin{description}
\item [Conditionals] A conditional is an if-then-else construct. We take these
  for granted now. They were invented by McCarthy in the course of developing
  Lisp. (Fortran at that time only had a conditional goto, closely based on the
  branch instruction in the underlying hardware.) McCarthy, who was on the Algol
  committee, got conditionals into Algol, whence they spread to most other
  languages.
\item[A function type] In Lisp, functions are first class objects-- they're a
  data type just like integers, strings, etc, and have a literal representation,
  can be stored in variables, can be passed as arguments, and so on.
\item[Recursion] Recursion existed as a mathematical concept before Lisp of
  course, but Lisp was the first programming language to support it. (It's
  arguably implicit in making functions first class objects.)
\item[A new concept of variables] In Lisp, all variables are effectively
  pointers. Values are what have types, not variables, and assigning or binding
  variables means copying pointers, not what they point to.
\item[Garbage Collection] 
\item[Programs composed of expressions] Lisp programs are trees of expressions,
  each of which returns a value. (In some Lisps expressions can return multiple
  values.) This is in contrast to Fortran and most succeeding languages, which
  distinguish between expressions and statements.

  It was natural to have this distinction in Fortran because (not surprisingly
  in a language where the input format was punched cards) the language was
  line-oriented. You could not nest statements. And so while you needed
  expressions for math to work, there was no point in making anything else
  return a value, because there could not be anything waiting for it.

  This limitation went away with the arrival of block-structured languages, but
  by then it was too late. The distinction between expressions and statements
  was entrenched. It spread from Fortran into Algol and thence to both their
  descendants.

  When a language is made entirely of expressions, you can compose expressions
  however you want. You can say either (using Arc syntax)

  \begin{lstlisting}[style=lispinline]
    (if foo (= x 1) (= x 2))
  \end{lstlisting}

  or

  \begin{lstlisting}[style=lispinline]
    (= x (if foo 1 2))
  \end{lstlisting}

\item[A symbol type] Symbols differ from strings in that you can test equality
  by comparing a pointer.
\item[A notation for code] using trees of symbols.
\item[The whole language always available] There is no real distinction between
  read-time, compile-time, and runtime. You can compile or run code while
  reading, read or run code while compiling, and read or compile code at
  runtime.

  Running code at read-time lets users reprogram Lisp's syntax; running code at
  compile-time is the basis of macros; compiling at runtime is the basis of
  Lisp's use as an extension language in programs like Emacs; and reading at
  runtime enables programs to communicate using s-expressions, an idea recently
  reinvented as XML.
\end{description}

Given only the original paper, it is unclear whether or not functions had a
separate data type, as Graham implies.  The paper seems to suggest that a
function is simply a list which happens to be called or evaluated.  This is
still possible in at least some Lisps, \el{} among them.  \footnote{Note that
  this does not mean that a function is necessarily merely a list of a
  particular form, or that any guarantees on the form are given.}  The point
Graham makes stays though: it was possible to create functions at runtime and
pass them around as any other value.

Lisp was originally supposed to adopt a different syntax, especially for
function calls and definitions.  McCarthy even used this syntax, called
M-expressions, in his original paper \cite{rec-fun-sym-expr}.  They were to be
translated into S-expressions (short for Symbolic expressions).  While in the
original paper the syntactic representation of S-expressions and lists was
slightly different, they essentially had their current form, namely consisting
of symbols and lists, using a prefix scheme, i.e. having the operator as the
first element of a list.

McCarthy himself used the term S-expression for symbols, while today most Lisp
programmers use the term S-expression, or sexp for short, to mean any string of
characters which may be read by a Lisp implementation.  The latter meaning will
be used in this thesis from now on.

This proposed translation was not merely a syntactic, let alone cosmetic change.
Compilers and interpreters in general need some form of source representation
which is above the character level of the source code which they take as input.
This is typically called an abstract syntax tree (AST)\footnote{The exact
  differences and relationships between ASTs, concrete syntax trees and the like
  are beyond the scope of this thesis.}.  Lisp, being a dynamically typed
language, allows the syntax tree to be particularly simple.  While a tree in a
statically typed language may need structures to differentiate between a
function call (which has a name and one or more arguments), and a number
literal, in Lisp one can simply use dynamic typing.  This way, numbers, strings,
symbols etc. can be put directly in place, while nested lists provide the tree
structure needed.

As Lisp programs can be represented with data structures which Lisp provides,
higher-order programs became possible quite early in the history of computers.
Lisps syntax and its relationship to metaprogramming is discussed in further
detail in section \ref{sec:lisp-basics}.

\section{What is Emacs?}
\label{sec:emacs-intro}

Emacs was at first a text editor at MIT, written in machine language and
extensible with an interpreted command language.  The interpreter was taken from
TECO, another text editor used at MIT at the time.  According to Stallman there
was an implementation on a Lisp Machine and later on Multics.  Both of these
were written in Lisp, hence were extensible in Lisp.  When Stallman started the
GNU project, he needed an implementation for \unix{}.  While Lisp compilers were
somewhat available, they could not perform runtime type checks at the same speed
as Lisp Machines could, hence one had to choose performance or safety, but could
not have both. \footnote{Why Stallman felt that using C instead of an optimizing
  Lisp compiler is beyond me.  Both suffer from the lack of type checking, while
  using Lisp would have been far more productive than programming in C.
  Possibly the lack of decent free Lisp compilers played a part in this
  decision.} Stallman decided to write a Lisp interpreter and editor primitives
like display handling in C, while writing as many higher level functions as
possible in Lisp.  The dialect he designed and implemented is called \el{}, or
elisp for short\footnote{Note though, that there once was an unrelated dialect
  of the name elisp.}\cite{emacs-hist}.  In 1984 Stallman wrote what is now
known as GNU Emacs.\cite{emacs-first-release} Since then, \el{} has grown and
changed a lot.

While Emacs is primarily a text editor, it achieves its extensibilty by
being/providing a virtual Lisp Machine.  So far only some experimental features
exist to incorporate shared objects into a running instance of Emacs, so the
only ways to add features is to modify the C code base, which requires
recompilation, or by loading \el{} code.  All C functions which users may need,
are exported to Lisp, and are largely indistinguishable from Lisp functions,
macros or special forms.  This extensibility has made Emacs one of the most
powerful editors available.  For the rest of this thesis, the editing
capabilities of Emacs are rather unimportant.  The thesis will concentrate more
on the Lisp Machine part of Emacs.

The capabilities of \el{} have drastically improved over the last years.  Until
Emacs 24.1 \el{} only featured dynamic scope\cite{Emacs-Lexical}. \footnote{See
  \cite{CLTL2}
  (\url{http://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node43.html})for an
  explanation of why ``dynamic scope'' is a misnomer, yet still useful as a
  term.  While the differences in scope and extent are interesting, they are not
  relevant to this thesis.}  In the version of Emacs which will probably be
named 25.1 Emacs will also feature \cl{} style multimethods.  As these methods
were used for the code in this thesis, said code requires at least a pretest
version of Emacs\cite{emacs-pretest}.

\section{What makes Lisp special}
\label{sec:lisp-basics}

As outlined at the end of section \ref{sec:lisp-hist}, Lisp code can be
represented in its own data structures.  This sets it apart from most (if not
all) mainstream languages in use today. As this is vital to the rest of this
thesis, it is discussed in detail here.

As an example, we will transform a simple algebraic expression.  The simple
expression \(a + b * c\) put into tree form can be seen in figure
\ref{fig:simple-tree}.

\begin{figure}[h]
  \centering
  \begin{tikzpicture} %[every node/.style = {shape=circle, draw}]
    \node [op] {+} child { node [arg] {a} } child { node [op] {\times}
      child { node [arg] {b} } child { node [arg] {c} } };
  \end{tikzpicture}
  
  \caption{Tree form of an algebraic expression}
  \label{fig:simple-tree}
\end{figure}

Given lists of arbitrary length, symbols and dynamic typing, the same tree may
also be represented like this:

% Given a list notation as used in Lisp, i.e. parentheses and spaces which delimit
% elements, together with prefix notation, it may as well look like this:

\begin{lstlisting}[style=lispinline]
  (+ a (* b c))
\end{lstlisting}

Note that precedence of multiplication over addition is implicit in the
algebraic form (i.e. must be known to any human or program attempting any
transformation), yet explicitly given in both tree diagram and list
representation.  Given that Lisp syntax is given as nested lists, symbols and
prefix notation, is becomes apparent that Lisp only has syntax for an AST.  This
means that programmers do not enter syntactic forms, but directly enter the AST
for their programs.

This may put off some programmers as unaesthetic\footnote{Many non-lispers claim
  that Lisps syntax---or lack thereof---is difficult to read, yet I and many
  other Lisp programmers disagree.  Once a programmer has become accustomed to
  this kind of source code, it can become quite appealing, and the parenthesis
  are not as intrusive to the mind as many initially suspect.}.  While it is
difficult to meaningfully argue over such subjective topics, there are technical
advantages to this approach.

The advantages come in at least four categories:

\begin{enumerate}
\item Possibility of higher order programs, i.e. macros.
\item Possibility of communicating via sexps, similar to XML.
\item Possibility of very powerful editing tools.
\item Possibility of a customizable syntax.
\end{enumerate}

The first category enables programs which transform and write programs.  This
can even happen at runtime, if needed, and---depending on the particular Lisp
implementation---may even be compiled at runtime to provide high speed.

The second category simply means that data may be printed and read back in the
languages own syntax, without having the need to devise an own syntax along with
a parser.  This also frees the programmer from having to learn another language.

The third category is---for the most part---beyond the scope of this thesis,
although the customizability of the languages syntax does pose a problem for
such tools.  The gist of these tools is that they can view the source code in a
similar fashion as the reader does: as a tree of expressions.  Such tools
attempt to disallow and thus prevent the user from making any changes to the
source, which would result in an incorrect tree.  This does not mean that the
source will always be free of errors: function calls may still have too many or
too few arguments, functions or variables may be undefined.  Yet it is not
possible to have too many opening or closing parens.

These tools offer tremendous editing power, as they allow the programmer to
perform operations on a tree.  Two examples of such tools for Emacs are
paredit\cite{paredit} and lispy\cite{lispy}.  Both these tools are for Emacs and
both are primarily directed at \el{}.  Yet because of the simplicity and
(syntactic) similarity of Lisps, both tools can also be used for other Lisps
like \cl{}, albeit with some restrictions and annoyances.\todo{add a reference
  to the appropriate section, should I opt to add one.}

The fourth category it the subject of this thesis.  Before discussing how an
extensible reader works, it is necessary to first understand what a reader does,
whether it is extensible or not.

\subsection{The reader}
\label{subsec:reader}

The reader is a part of a Lisp system.  As outlined before, a string of
characters (source code) is transformed into an AST in any language.  In Lisp,
the syntactic layer is very thin, which makes the structure of the resulting AST
apparent in the source code, as no special constructs are needed for loops,
function definitions, types or the like.

\subsection{Print syntax}
\label{subsec:print-syntax}

The printer is a part of a Lisp system, which works in tandem with the reader.
While a reader converts a textual representation into an object, the printer
converts an object into a textual representation.

As Lisp systems tend to be highly interactive, most lisps provide a means to
print values to a stream.  What Lisp does is slightly different to what many
other languages offer, as Lisp can often print back values in a way which are
valid input syntax.  How a data type is printed depends on the Lisp dialect.
Also not every dialect can print every data type.  Common Lisp by default cannot
print hash tables, and hardly any lisp has a meaningful printed representation
for functions---\el{} being an exception here.

Lists are among the types which have not only meaningful print syntax, but also
one, which is compatible with its read syntax.  This means that a list, as shown
above, looks the same when printed, as it did in the source code---with minor
exceptions, which have to do with evaluation.  The details of reading and
evaluation are discussed later\todo{add ref}.  For now it is sufficient to say,
that reading the expression 

\begin{lstlisting}[style=lispinline]
  (+ a (* b c))
\end{lstlisting}

results in a Lisp object.  When this object is printed back, it looks (almost)
exactly the same\footnote{A few things, such as comments and indentation are
  lost, but otherwise it looks the same.}.  In Emacs, this can easily be tried
out: In the *scratch* buffer, put the following expression: \textbf{(read "(+ a
  (* b c))")}, place the cursor on the end of the expression and press C-c C-e.
The very same text should appear on the status line.  The same can be done in
almost any lisp environment in some form.  

This allows users to print data to a file or network and read them back in
again.  This is what Paul Graham meant when he claimed that programs
communicating via sexps was an idea recently reinvented by XML.

\begin{comment}
  The reason why lisp code has so many parentheses, is that parentheses denote a
  list in Lisp.  Expressions in general, save the most trivial ones, are
  represented of lists containing other lists and symbols.\footnote{Plus of
    course other entities such as numbers, yet these are not relevant to this
    discussion.}
\end{comment}
% \section{Introduction}
% \label{sec:introduction}

% This thesis discusses the design, implementation, and idiosyncrasies of \elr{},
% an extensible reader for \el{}.  An overview over the history of Lisp, Emacs and
% \el{} are given, as well as an introduction to 

% \section{Introduction}
% \label{sec:introduction}
% In this thesis, a \cl{} like extensible reader for \el{} is discussed.  Before
% discussing the reader itself, it is important to discuss what a reader does,
% what it can do, and how the built-in reader in \emacs{} differs from the
% extensible one discussed in this thesis, or the \cl{} reader, from which this
% reader draws its inspiration.

% For this purpose, Lisps syntax, and how it is different from almost all other
% languages, is discussed.

% It is also shown what can be done with such an extensible reader, and why one
% might want to use such extensions.

% The application of such an extensible reader allows the creation of new
% syntactic constructs, which may be embedded into the language.  Thus, it enables
% the user to not only create a DSL, but also to embed it into a greater program,
% without making the new constructs opaque by putting them into strings, which
% must be parsed at runtime.


% In this thesis, the author wishes to first convey how Lisps syntax is different
% from other languages and why this is relevant to the discussion of extending the
% syntax.  Secondly what is meant by an extensible syntax or read macro, and why
% they might be relevant.  Also, depending on the background of the reader of this
% text, one might confuse such syntactic extensions with Domain Specific
% Languages—or DSLs for short.

% While there is some overlap between the two, DSLs are not necessarily embedded,
% but instead may come with a separate compiler and/or interpreter.  An extensible
% syntax, as it is presented here, allows to change the syntax on-the-fly,
% possibly without altering any present syntactic constructs, thus allowing new
% constructs in an existing programming language.

\section{Terminology}
\label{sec:terminology}

To get things out of the way, we first define some terms:
\begin{description}
\item[Terminating macro character] A character which has been marked as a
  terminating macro character must have a function attached to it, even if this
  function only signals an error when called.  Such characters also terminate
  any token which occurs before them.  If, for instance, `(' is such a
  character, the character sequence ``bar(...'' will stop reading between the
  `r' and `(', resulting in the symbol \sym{bar}.

  If such a character is encountered as the first char to \fun{read}, its
  associated function is called.
\item[Non-terminating macro character] These characters work in a similar
  fashion to Terminating macro characters, yet do not terminate a token
  preceding them.  Also their associated function is not called in such a
  situation.
\item [Read macro] A read macro is a pair of a (non-)terminating macro character
  and a function, which is associated with it.  The two together create the
  possibility to define new syntactic constructs.
\item[List] In Lisp parlance, a list almost always means a singly linked list,
  i.e. a collection which can grow and shrink at the front by one element in
  constant time.
\end{description}

\section{Motivation}
\label{sec:motivation}
Users of other Lisp dialects, especially of \cl{}, have enjoyed the possibility
to modify the syntax they use to write programs for a long time.  This
possibility provides a huge benefit in the course of evolving a language, as
well as implementing readers for custom languages.  Macros---which are expanded
at compile-time---provide a very powerful mechanism for code generation.  These
allow to control the order of evaluation of forms within the macro, as well as
the opportunity to transform them, yet sometimes even this kind of power is not
quite enough, as the macro call must still consist of valid s-expressions.

A very simple case is the addition of syntax for data structures, since this is
what the reader is there for anyway: transforming characters into data
structures.  Most modern programming languages provide some syntax to enter hash
tables.  Take for instance python, where the keys and values may be specified
between curly braces:

% \begin{minted}[]{python}
% {"foo": "bar", "five": 5}
% \end{minted}

\begin{lstlisting}[style=pythoncode]
{"foo": "bar", "five": 5}
\end{lstlisting}

When entered into a python interpreter, this expression returns a hash table (or
Dictionary in Python terminology).

Clojure, a rather recent addition to the Lisp family of languages also features
a similar syntax:

% \begin{minted}[]{clojure}
% {"foo" "bar" "five" 5}
% \end{minted}

\begin{lstlisting}[style=lispinline]
{"foo" "bar" "five" 5}
\end{lstlisting}

This also returns a mapping from keys to values.

Unfortunately, neither \cl{} nor \el{} feature such (concise)
syntax\footnote{\el{} has read (and even print) syntax for hash tables, yet is
  is rather ugly.  The same table looks like this: \#s(hash-table size 65 test
  eql rehash-size 1.5 rehash-threshold 0.8 data ("foo" "bar" "five" 5))}.  \cl{}
users may create such a syntax themselves, yet \el{} users never had this
possibility.

In the absense of read macros, one possible shortcut is to simply define a
function to do so; consider the function \fun{ht} in listing \ref{code:cl-ht}
from the source code of this thesis, ported to \cl{}.

% \begin{listing}[h]
% \caption{Creating a hash table.}
% \label{mint:cl-ht}
% \begin{clcode}
% (defun ht (&rest args)
%   "Create and return a hashtable.

% Keys and values are given alternating in args."
%   (let ((h (make-hash-table)))
%     (loop for (key value) on args by #'cddr
%        do (if (and key value)
%               (setf (gethash key h) value)
%               (error "Odd number of arguments passed")))
%     h))
% \end{clcode}
% \end{listing}

\begin{lstlisting}[style=lispcode,caption={Creating a hash
  table.},label={code:cl-ht}]
(defun ht (&rest args)
  "Create and return a hashtable.

Keys and values are given alternating in args."
  (let ((h (make-hash-table)))
    (loop for (key value) on args by #'cddr
       do (if (and key value)
              (setf (gethash key h) value)
              (error "Odd number of arguments passed")))
    h))
\end{lstlisting}
This may be used as

% \begin{clcode}
% (ht "foo" "bar" "five" 5)
% \end{clcode}

\begin{lstlisting}[style=lispinline]
(ht "foo" "bar" "five" 5)
\end{lstlisting}


instead of the more cumbersome and repetitive code shown in listing
\ref{code:cl-canon-ht}.

% \begin{listing}[h]
% \begin{clcode}
% (let ((h (make-hash-table)))
%   (prog1 h
%     (setf (gethash "foo" h) "bar")
%     (setf (gethash "five" h) 5)))
% \end{clcode}
% \caption{Canonical way to create a hash table.}
% \label{mint:cl-canon-ht}
% \end{listing}

\begin{lstlisting}[style=lispcode,caption={Canonical way to create a hash
  table.},label={code:cl-canon-ht}]
(let ((h (make-hash-table)))
  (prog1 h
    (setf (gethash "foo" h) "bar")
    (setf (gethash "five" h) 5)))
\end{lstlisting}

To further shorten and clarify the creation of hash tables, \cl{} users may use
a read macro. Listing \ref{code:cl-hash-reader} shows how this may be done
(assuming \fun{ht} has been defined as in listing \ref{code:cl-ht}).
\footnote{The details of this code are not of particular importance, merely that
  it is possible, and quite short.}

\begin{lstlisting}[style=lispcode,caption={A \cl{} read macro to read hash
  tables}.,label={code:cl-hash-reader}]
(set-macro-character #\} (get-macro-character #\)))

(set-macro-character
 #\{
 (lambda (stream char)
   (declare (ignore char))
   (let ((k-v (read-delimited-list #\} stream t)))
     (if (oddp (length k-v))
         (error "Invalid syntax: {}")
         `(ht ,@k-v)))))
\end{lstlisting}

Now the \cl{} reader reads ``\{\ldots{}\}'' constructs in a similar fashion as
the Clojure reader does.

Given \elr{}, i.e. the code from this thesis, the code in listing
\ref{code:el-hash-reader} may be used in \el{} to produce the same effect.

\begin{lstlisting}[style=lispcode,caption={An equivalent read macro using
  \elr{}.}, label={code:el-hash-reader}]
(defun ht (&rest args)
  "Create and return a hashtable.

Keys and values are given alternating in args."
  (let ((h (make-hash-table)))
    (cl-loop for (key value) on args by #'cddr
             do (if (and key value) (puthash key value h)
                  (error "Odd number of arguments passed")))
    h))

(el-reader/set-macro-character
 ?\} (car (el-reader/get-macro-character ?\))))

(el-reader/set-macro-character
 ?\{
 (lambda (stream _char)
   (cl-values
    (let ((k-v (el-reader/read-delimited-list ?\} stream t)))
      (if (= (mod (length k-v) 2) 1)
          (error "Invalid syntax: {}")
        `(el-reader//ht ,@k-v))))))
\end{lstlisting}

Note the similarity of the API.  The prefixes have been put in place, as \el{}
provides no packaging facilities.\footnote{Should Emacs change the internal
  representation of symbols, packaging may be possible, given this reader, yet
  is beyond the scope of this thesis.}

A more sophisticated use case might be to provide read syntax for regular
expressions---regexps for short.  In \el{} regexps are notoriously ugly to enter
and read, because they are opaque strings, which are passed to a function, which
parses it at runtime.  This means that many constructs must be escaped multiple
times, which makes the strings difficult to read and write.  A particular
notorious offender is the regular expression which matches a single backslash;
in Clojure one may write \texttt{\#"\textbackslash\textbackslash"}, \el{} users
are forced to write the much more cumbersome
\texttt{"\textbackslash\textbackslash\textbackslash\textbackslash"}.  Here again
Clojure shows a nice way to handle the issue: by providing syntax for them.

While Clojure provides more syntax than \el{} does, and more than \cl{} does out
of the box, it provides no way for users to add their own constructs.

Finally, it is also possible to define non-standard evaluation semantics, as the
code for read macros is run at read time.  This means that calculations may be
performed at read time, which---when using ahead of time
compilation---translates to compile-time.

An example for this is something similar to rubys \texttt{\%w} construct.  It
reads a list of tokens, converts them to strings and makes an array out of
them.  

\begin{lstlisting}[style=rubyinline]
%w(foo bar spam and eggs) 
# => ["foo", "bar", "spam", "and", "eggs"]
\end{lstlisting}

While ruby is very flexible about the delimiters, one might define
\texttt{\#w(...)} in Lisp as in listing \ref{code:elr-ruby-words}

\begin{lstlisting}[style=lispcode,caption={A read macro for rubys word
  syntax.}, label={code:elr-ruby-words}]
(defvar *my-read-stuff/word-seq-types*
  {'cons #'list 
   'vector #'vector})

(defun my-read-stuff/read-words (stream char _num)
   (let ((words (el-reader/read stream t nil t)))
     (if (not (seqp words))
         (error "Invalid syntax: #w")
       (cl-values
        `(quote
          ,(apply
            (gethash (type-of words)
                     *my-read-stuff/word-seq-types*)
            (seq-map (lambda (s)
                       (if (not (symbolp s))
                           (error "Invalid syntax: #w")
                         (symbol-name s)))
                     words)))))))

(el-reader/set-dispatch-macro-character
 ?# ?w
 #'my-read-stuff/read-words)
\end{lstlisting}

While this version uses different delimiters for different types of return value
(parentheses form a list, square brackets form a vector), it can only use
certain delimiters, namely those which have read syntax for a sequential data
structure.  On the other hand it is extensible in the types it provides, and
most importantly forms the structure at read-time.  This may be of some worth
for large constants.

Here is how it is used:

\begin{lstlisting}[style=rubyinline]
#w(foo bar spam eggs) => ("foo" "bar" "spam" "eggs")
#w[foo bar spam eggs] => ["foo" "bar" "spam" "eggs"]
\end{lstlisting}

\section{Lisp Basics}
\label{subsec:lisp-basics}

This section is only intended as a short recap of what Lisp syntax is, and how
it relates to the reader.  For more details, a Lisp textbook is more
appropriate.  A good reference for \el{} is found at \cite{elisp-reference}.
The chapters 

Lisp syntax never directly describes control flow, function definitions, or
other actions, but merely data.  If the described data consists of lists and
symbols, it will later on be treated as code, which can be compiled and
executed.\todo{Possibly show some Lisp examples.}

Such data structures can represent code by having a list with an ``action'',
which may be a special form, a macro or a function, as its first element.  Any
further elements are arguments to said operator.

As an example, here is some code which performs a variable binding with
\fun{let} (which is a special form), an assignment with \fun{setf} (a macro) and
a function call to \fun{message}.

\begin{lstlisting}[style=lispinline]
(let ((var 5))
  (setf var "Hello")
  (message "%s" var))
\end{lstlisting}

When Lisp source code is processed, it goes through three distinct stages:
reading, macro expansion (optionally this can also be a compile phase), and
evaluation (which can be the execution of compiled code).

The first stage is somewhat unique to Lisp---most languages only have this as an
implementation detail in the compiler or interpreter.

\subsection{Reader}
\label{subsec:reader}

The reader is the first stage which code runs through.  This part of the
evaluation mechanism is the only part which sees individual characters.  As Lisp
syntax consists of literal representation of data, not of control structures and
the like, the reader transforms these literal representations into data
structures, which may be treated as executable code later on.

The reader is the part of the evaluator which knows that parentheses denote
lists, square brackets denote vectors, how to read numbers, symbols and so on.

It also defines where a token ends, in the absence of whitespace. For instance,
the following expressions are all slightly different textual representations of
the same object, i.e. later stages cannot distinguish between the two.

\subsection{Macro expansion}
\label{subsec:macro-exp}

\subsection{Evaluator}
\label{subsec:evaluator}



\section{Reader basics}
\label{sec:reader-basics}

Before discussing what the reader is and what it does, it is important to first
introduce a few important data types.
\subsection{Important Lisp Data Types}
\label{subsec:important-types}

A few Lisp data types are of particular importance, both because they are
relatively rare in other languages, but also because they are very widespread in
Lisp code, i.e. the reader often creates them.

Every Lisp dialect the author is aware of provides at least the following:

\subsubsection{Symbols}
\label{subsubsec:symbols}

The symbol is a type, which represents a name, often together with places for
values and/or functions.  The latter depend on the Lisp dialect.  An important
property of symbols is that fast lookup is supported, and that symbols are
interned.  This means that each symbol which is read, which has the same name,
returns the same Lisp object.\footnote{This is, in effect, a singleton.}

In \el{}, which is the Lisp under consideration for this thesis, a symbol has
the following attributes:

\begin{description}
\item[{Name}] A (typically hashed) name for the symbol.  This may be retrieved
  as a string at any time.
\item[{Value}] This is the value of the symbol.  It may be retrieved by a call
  to \fun{symbol-value} or by simply appearing in a program (macros or special
  forms may treat symbols differently).
\item[{Function}] This cell is looked up if the symbol is the first element of a
  list which is evaluated (more on this later).  Alternatively, a call to
  \fun{symbol-function} returns the function to which it points (if any).
\item[{Property List}] A symbol may also have a Property List, or plist for
  short, which is a mapping from a key (mostly a symbol) to a value.  This is
  intended as a mechanism to store arbitrary metadata in a symbol.
\end{description}

\subsubsection{List}
\label{subsubsec:list}

In Lisp parlance, when a list is mentioned, it is almost always a singly linked
list.  While by far not the only compound data structure\footnote{Strictly
  speaking, lists by themselves to not exist: there are only cons-cells, yet
  this nuance is not very important for the current discussion.}, it is a very
important one.

Not only is there syntax for lists---in the form of parentheses---together with
the symbol, the list is used as the prime representation for code.  The
following section hat some examples, as it discusses the result of calling the
reader.
\subsection{Lisp basics}
\label{subsec:lisp-basics}

This section is about a few basics of Lisp, not so much the reader.  Here it is
discussed how nested lists can represent such actions as function calls,
assignment and function definitions, as Lisp does not have any syntax for those.
\paragraph{Function call}
\label{par:function-call}

In Lisp a function call happens when the evaluator comes across a list form.  In
such a case the first element is taken to be a function and the other elements
are its arguments.  Here is the canonical hello world program for \el{}:

\begin{lstlisting}[style=lispinline]
(print "Hello, world")
\end{lstlisting}

Here we have a list of two elements.  The first element happens to be a symbol,
which has a function associated with it.  The second element (a string in this
case) is evaluated (nothing special happens here, as strings evaluate to
themselves, contrary to lists) and passed as the sole argument to the function
named by the symbol print.

\paragraph{Assignment}
\label{par:assignment}

An assignment is either a special form, i.e. a primitive which the
implementation must provide, or a macro (which expands to other code, eventually
leading to a special form).  Here the low level special form was chosen.  To
assign the value 5 to the ``variable'' \sym{x} with a such a low level special
form, we could write the following:

\begin{lstlisting}[style=lispinline]
(set (quote x) 5)
\end{lstlisting}

The \fun{quote} form around \sym{x} tells the evaluator to \emph{not} evaluate
\sym{x}, but to pass it on as the symbol itself.  Note that the reader would
have created the symbol \sym{x}, and only the evaluator can care about any
meaning for \sym{x}.  Many language implementations throw symbols away at
runtime.  This is also possible in Lisp, as the compiler can remove symbols and
their lookups in many situations.

Note that although \fun{set} is a special form, it too is invoked when it is the
first element in a list.  Like macros, but unlike functions, special forms may
control how to evaluate their arguments.

\paragraph{Function definition}
\label{par:function-def}
Unsurprisingly, a function is defined by a list form, with a special symbol as
its first element.  In \el{} this symbol is \fun{defun}.

\begin{lstlisting}[style=lispinline]
(defun say-hello (text)
  (print text))
\end{lstlisting}

Note that the third element, although it is a list, is neither evaluated, nor
must it be quoted.  This is because \fun{defun} is a macro, and macros may
control how to evaluate their arguments.

\subsection{What does the reader do?}
\label{subsec:what-does-the-reader-do}
In a sense, every programming language has a reader.  Every language
implementation must provide some means of converting characters in source code
into data structures which are more meaningful to the later stages of
interpretation or compilation.

The difference in Lisp is that the reader is available to the programmer both at
runtime and compile time (if there is a compile phase).

This means, that an application may store data structures by printing them (for
instance to a file) and later reading them back.  If one had a list, containing
the symbol \sym{foo}, the number 3, the symbol \sym{bar} and the string "4",
printing might result in this: \footnote{The exact form depends on the dialect.
  If not otherwise stated, is assumed.  is also used extensively.}

\begin{lstlisting}[style=lispinline]
(foo 3 bar "4")
\end{lstlisting}

This may later be read back with a call to \fun{read}, to retrieve a data
structure, which has the same shape as the original.  Note that this is not
syntax for code in the sense of execution, yet merely for data.  This is an idea
which pervades Lisp, as code is data, and data may be code.

If the code which was read in this example were to be evaluated (by calling
\fun{eval} on the result of the call to \fun{read}), \sym{foo} would be expected
to name a function, and \sym{bar} would be evaluated as a variable.  The
function named by \sym{foo}, if any, would then be called with the argument 3,
whatever \sym{bar} evaluated to, and the string "4".

The strict distinction between \emph{reading}, and \emph{evaluating} code is
what makes read macros possible.  It is also the reason for the parenthesis in
typical lisp code.  This is because the list (denoted by parenthesis) is the
structure in which code is held.  This is true for assignments, function calls,
function definitions etc.  Examples are given below.

\subsection{Properties of Lisp Syntax}
\label{subsec:properties-of-lisp-syntax}

The idea behind the syntax of Lisp is very different than in most other
programming languages.  While most languages provide constructs for assignment,
looping, function definition, etc, Lisp merely provides syntax for data
structures.  This idea has been reused in data description languages such as XML
and JSON, among others.  An expression in source form, which describes a Lisp
object is also called a symbolic expression, or sexp for short.  The term form
is also used on occasion.

So far, no evaluation rules have been discussed, and rightly so.  The evaluation
of code is not something the reader takes part in.  This is left to the
interpreter or the compiler.

\subsection{Intermezzo: syntax at runtime}
\label{subsec:intermezzo:syntax-at-runtime}

While some programming environments allow the user to load code at runtime, Lisp
also allows to read and compile code at runtime.  The former is exposed by a
function called \fun{read}.  This function is given at least one argument:
something which may be used to retrieve a character, and to put back at least
one character which has been read.  This function attempts to read one Lisp
object from the character stream, and returns said object if successful.

This aspect may be compared to an XML parser, which also merely describes data.
One difference is that a Lisp reader can be more flexible, as this thesis shows.
A further difference is that standard Lisp syntax\footnote{Standard syntax
  refers to the set of rules present when no modification has taken place since
  a fresh start of the environment.} is shorter when a lot of markup is needed.
I.e. writing programs in XML tends to be rather verbose, as such languages as
ant show \cite{ant}.  Writing a document in symbolic expressions would probably
be rather cumbersome, as either lots of strings must be used, or elaborate rules
for the treatment of special chars as apostrophes must be devised.

\subsection{Reader, Compiler, Interpreter}
\label{subsec:reader-compiler-interpreter}

In this section, an overview over the reader, compiler and interpreter, together
with their interactions is given, as it is relevant to the central point of the
thesis.

\section{Why Emacs?}
\label{sec:why-emacs}

The author chose to extend Emacs with an extensible reader, and not some other
member of the Lisp family, such as Clojure for several reasons.  One reason is
that the author has gained the most familiarity with \el{} and \cl{}.  The two
are reasonably similar in a number of ways, especially with \el{} growing a lot
in recent years.  \el{} used to have only dynamic scope, yet gained optional
lexical scope in version 24.1\cite{Emacs-Lexical},% \footnote{See
  % \url{https://www.gnu.org/software/emacs/news/NEWS.24.1}}
giving \el{} both lexical and dynamic scope, as with \cl{}.  Also, in the next
version of Emacs, which will probably become version
25.1\cite{emacs-pretest},% \footnote{See
  % \url{http://permalink.gmane.org/gmane.emacs.announce/59} for a source tarball.
  % It contains a file etc/NEWS which details changes}
CLOS-style multiple dispatch generic functions have been added, which ease
development for many scenarios and again are a step towards \cl{}.

\el{} is also quite similar to \cl{} in many other rather minor respects.  Both
are a Lisp-2\footnote{Being a Lisp-2 means having separate namespaces for
  functions and variables.}, both use \sym{defun} to define functions and
\sym{defmacro} to define macros, both with a very similar and largely compatible
grammar.  \el{} also sports a built-in package called CL which tries to emulate
many \cl{} features, such as more features for default arguments, destructuring,
and the \cl{} \fun{loop} macro.

Emacs still has a long way to go before being as powerful as \cl{}, and probably
never will be, as multithreading, conditions and restarts, full CLOS support,
packages and some minor issues like returning multiple values and global symbol
macros are still missing.

As Emacs also does not feature a built-in extensible reader, this thesis
provided one to hopefully drive Emacs development forward some more.

\section{Reader internals}
\label{sec:reader-internals}

While the reader has a very simple interface, internally it must keep some
state, in order to know how to treat the characters encountered.  Some ephemeral
state is kept on the call stack and in closures, but the more important state is
kept in a structure called a readtable.

The readtable enables users to modify this state.  While it is possible for a
user to modify this structure directly, it is strongly discouraged.  Emacs has
no possibility to prevent users from seeing or modifying state, but through
compiled closures.

As a convention, symbols which are part of the public API are prefixed with
``el-reader/'', while symbols which are not part of the public API are prefixed
with ``el-reader//''.  Some symbols also use a sort of sub-namespace, i.e. are
prefixed with ``el-reader//rt/''.  This helps users to distinguish between
public API and internals on the basis of a symbol name.

The public API consists mostly of functions like
\fun{el-reader/set-macro-character}, which manipulate a readtable.

Many of these functions take a readtable as an optional argument.  If no
argument is given, the current readtable is used.  The current readtable is a
special variable named \sym{*el-reader/readtable*}.  The default value of this
variable is a readtable which mimics \el{}s default syntax as closely as
possible.  While this has not been achieved at the moment, it is possible to
complete the table with more read macros.  The heavy lifting, such as reading
circular data structures is already present.  Also, the most common constructs
used in \el{} are present.  

The readtable provides the basis on which \elr{} decides how to treat
characters.  Characters have exactly one syntax type.

Note that not all characters which denote the same value have the same syntax
type and traits.  It is possible for a character (for instance when escaped) to
be treated as a constituent with the alphabetic trait, although it would
otherwise denote a macro character.  For instance: `(' is a macro character, but
if read as ``$\backslash$('', the open parenthesis will instead be treated as an
alphabetic constituent.  Traits such as alphabetic will be discussed in section
\ref{subsubsec:traits}.

\subsection{Syntax types}
\label{subsec:syntax-types}

Here all syntax types are listed.  These are very similar to the syntax types in
\cl{}, yet differ in a few points, as the main goal was not to parse \cl{} code,
but to be compatible to \el{}.

\subsubsection{Constituent}
\label{par:constituent}

Most characters are treated as ``constituent'' characters.  To be precise: if a
character does not have a different syntax type, it is constituent.  Constituent
characters may be part of a token.

Constituent characters also have traits, which will be discussed in the next
section.
\subsubsection{Invalid}
\label{subsubsection:invalid}

If the reader encounters an invalid character, an error is raised.  This does
not imply that no such char may be in the input stream.  A read macro may choose
to skip such characters, or may use them in creative ways.  This is completely
up to the user.  The default readtable does not specify any characters to have
the invalid syntax type.

\subsubsection{Whitespace}
\label{par:whitespace}

These are characters which serve no special meaning.  The name should be pretty
explanatory.

\subsubsection{Single escape}
\label{par:single-escape}

In standard \el{} a single escape char allows spaces and other characters which
do not comprise a symbol by itself to be part of one.  The sequence "foo bar"
would normally denote two tokens (from which two symbols will be created).
Should the desired name of \emph{one} symbol be "foo bar", a backslash is needed
(which is the sole default single escape char): "foo$\backslash$ bar" would read
as one token, not two.  This works in vanilla \el{}, although the author has
never seen this in the wild.

In \cl{} this is more important, as the reader up-cases all chars by default,
which escaping also inhibits.  This aspect of \cl{} was not incorporated into
\elr{}, as it is probably only present in \cl{} for historic reasons.

\subsubsection{Multiple escape}
\label{par:multiple-escape}

These chars are similar to single escape chars.  While a single escape only
escapes the next char, a multiple escape char escapes all chars up to the next
multiple escape char.  In \cl{} the `|' character is used by default, in
\elr{} the functionality is present, yet no character has been assigned, as
most users would not expect the pipe character to behave in such a way.

\subsubsection{Terminating macro character}
\label{par:terminating-macro-char}

These characters are what make read macros so interesting.  Every macro
character has an associated function, which is called with the character and the
current stream as arguments.

A function associated with a macro char may have no side effects apart from
advancing the stream, as such a function may make no assumptions about the
number of times an object is read.  Such a function may read one char at a time,
put back one read char which it has just read, and call \fun{read} on the
(possibly advanced) stream.

The function which is associated with a macro character shall return the read
object.

Terminating macro characters also terminate any token which may have been read
before encountering the macro character.  For example, `(' is a Terminating
macro character, which reads a list.  When the reader encounters the string
"foo(\ldots{}" it reads the constituents `f' `o' and `o'.  When `('---which is a
\emph{terminating} macro character---is encountered, it is put back into the
stream, and "foo" is treated as a token.  In the next call to \fun{read} (should
there be any), the function associated with `(' will be called, which in turn is
the result of the read call.

\subsubsection{Non-terminating macro character}
\label{subsubsec:non-terminating-macro-char}

These characters are very similar to \emph{terminating} macro characters.  The
only difference is how such a character is treated when constituents have been
read.  While reading a token, a terminating macro character is put back into the
stream and the already read characters form a token.  When a
\emph{non}-terminating macro character is encountered, the character is treated
as if it was a constituent and its function is \emph{not} called.  If no
constituents have been read before, an non-terminating macro character is
treated the same as a terminating macro character.


\subsubsection{Traits}
\label{subsubsec:traits}

Every character which is a constituent also has one or more traits, which
provide further information on its use.

\paragraph{Alphabetic}
\label{par:alphabetic}

characters are characters which may appear in a token.  Escaping may force this
trait on an otherwise non-constituent character.

\paragraph{Digit}
\label{par:digit}

characters may be treated as a number, if they form a token, and they are
compatible with the input base.

\paragraph{Package marker}
\label{par:package-marker}

characters were only implemented because \cl{} has them.  The only character
with this trait is the colon.  As Emacs uses so called obarrays to intern its
symbols, and it is not possible to intern a symbol into more than one array
%\cite{no-multi-intern}
, it is not possible to clone \cl{}s packaging mechanism to Emacs.  Hence this
syntax type is not of particular importance.

\paragraph{Plus sign, minus sign, dot, decimal point, ratio marker and exponent marker}
\label{par:number-traits}

are used while constructing numbers.

\paragraph{Invalid}
\label{par:invalid}

Should a character with this trait be encountered, an error is thrown.  So far,
\elr{} does not specify any characters to be of invalid trait.

\section{API overview}
\label{sec:api-overview}

The API of \elr{} takes lots of inspiration from the corresponding API in
\cl{}, as the two languages are sufficiently similar, and \cl{} has a very
mature library.  Also, it may be expected that some \el{} developers are
familiar with \cl{} read macros.  Those who are not may benefit from the
similarity, as learning and reference material on \cl{} read macros seems to be
more widely available than for any other Lisp, probably due to its stable
standard.  \footnote{Paul Grahams book ``On Lisp''\cite[p.~224]{on-lisp}
  contains a chapter explaining both regular macros and read macros.}

\subsection{The readtable}
\label{subsec:readtable}

The only user visible data structure is the readtable.  In \cl{} this type has
non-enumerable types, while in \elr{} it is defined in terms of
\fun{defclass}, hence is enumerable and even has public attributes.  Most users
will need none of these.  They are mostly needed when creating a completely new
readtable from scratch.

\subsection{Functions}
\label{subsec:functions}

Here be dragons.

% \section{References}
% \label{sec:references}
% \begin{description}
% \item[{srfi-10}] \url{http://srfi.schemers.org/srfi-10/srfi-10.html}
% \item[{dynamic scope misnomer}] \url{http://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node43.html}
% \end{description}

\pagebreak
\bibliographystyle{abbrvdin}
\bibliography{references}

\end{document}
