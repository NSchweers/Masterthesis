\documentclass[a4paper,10pt,twoside]{report}
%\documentclass[b5paper,8pt,twoside]{article}
%\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage{fontspec}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage{cite}
\tolerance=1000
%\usepackage{minted}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{tikz}

\setcounter{secnumdepth}{4}

\usetikzlibrary{trees}
%\tikzstyle op=[draw, circle]
%\tikzstyle arg=[]
\tikzstyle op=[inner sep=0,draw,circle,minimum size=0.8cm,execute at begin node=$,execute at end node=$]
\tikzstyle arg=[minimum size=.6cm,inner sep=0,draw,circle,fill=gray!50!white]

\author{Nathanael Schweers}
\date{\today}
\title{Proof of Concept: An implementation of a reader for extensible syntaxes for Emacs Lisp}
% \hypersetup{
%   pdfkeywords={},
%   pdfsubject={},
%   pdfcreator={Emacs 25.0.91.1 (Org mode 8.2.10)}}

\newcommand{\el}{Emacs Lisp}
\newcommand{\cl}{Common Lisp}
\newcommand{\elr}{el-reader}
\newcommand{\sym}[1]{\texttt{#1}}
\newcommand{\fun}[1]{\texttt{#1}}
\newcommand{\emacs}{GNU~Emacs}
\newcommand{\emacsv}[1]{GNU~Emacs~#1}
\newcommand{\unix}{\textsc{unix}}
\newcommand{\windows}{MS Windows\texttrademark}
\newcommand{\Read}{\fun{read}}
\newcommand{\nil}{\sym{nil}}

% \newenvironment{myEnv} [2]
% {\begin{frame} \frametitle{#1} \framesubtitle{#2} \begin{center}}
% {\end{center} \end{frame}}

% \newenvironment{sourcecode} [2]
% {\begin{listing}[h] \label{#1} \caption{#2} \begin{verbatim}}
% {\end{verbatim} \end{listing}}

%\newminted{cl}{}

\lstset{         %
  language=Lisp, %
  frame=single,  %
  %float,         %
  captionpos=b}

\lstdefinestyle{lispcode}{
  language=Lisp,
  basicstyle=\scriptsize,
  frame=single,
  %float,
  captionpos=b,
  %stringstyle=\color{red},
  %keywordstyle=\bfseries\color{purple}
  showstringspaces=false
}

\lstdefinestyle{lispinline}{
  language=Lisp, 
  showstringspaces=false}

\lstdefinestyle{pythoncode}{
  language=python,
  basicstyle=\small,
  showstringspaces=false
}

\lstdefinestyle{rubycode}{
  language=ruby,
  basicstyle=\small,
  float,
  captionpos=b,
  showstringspaces=false
}

\lstdefinestyle{rubyinline}{
  language=ruby,
  basicstyle=\small,
  showstringspaces=false
}

\begin{document}

\maketitle
\tableofcontents

\begin{abstract}
  This thesis discusses the design and implementation of a proof of concept for
  an \el{} compatible reader for extensible syntaxes, in \el{}, named
  ``\elr{}''.  In Lisp parlance, the reader is the part of the
  interpreter/compiler, which converts the characters in the source code to data
  structures, which are then further processed.  In an extensible reader, new
  syntactic constructs may be defined.  These new constructs take effect when
  specific characters are encountered in the source code, and may interact with
  the existing reader to create arbitrary data structures which are later either
  interpreted or compiled by the Lisp environment.

  Some other languages feature such capabilities, of which \cl{} is most widely
  known.  Some Scheme implementations also provide these or similar
  possibilities, yet this is not part of the standard.  SRFI-10 provides a
  specific character sequence with which all read macros must
  start. \cite{srfi-10}

  In \cl{} the possibility to interact with the reader is called a read macro or
  reader macro, and this term will also be used throughout this thesis.

  \el{} does not provide reader macros.  As of the upcoming version 25.1 the
  reader is implemented in C and does not provide any hooks into it, apart from
  the usual advice system, which all \el{} functions provide.

  The code underlying this thesis provides a means to replace the reader built
  into Emacs.  The main point of this thesis is to show that the flexible nature
  of a Lisp environment may be used to replace even such a crucial part of the
  system as the reader at runtime, without affecting unrelated parts, or making
  the original part unavailable.
\end{abstract}

\chapter{A brief history of (GNU) Emacs}
\label{sec:emacs-intro}

Emacs was at first a text editor at MIT, written in machine language and
extensible with an interpreted command language.  The interpreter was taken from
TECO, another text editor used at MIT at the time.  According to Richard
Stallman \cite{emacs-hist} there was an implementation on a Lisp Machine and
later on Multics.  Both of these were written in Lisp, hence were extensible in
Lisp.  When Stallman started the GNU project, he needed an implementation for
\unix{}.  As Lisp programs on regular machines could not perform runtime type
checks at the same speed as Lisp Machines could, one had to choose performance
or safety, but could not have both.\footnote{Why Stallman felt that using C
  instead of an optimizing Lisp compiler is beyond me.  Both suffer from the
  lack of type checking, while using Lisp would have been far more productive
  than programming in C.  Possibly the lack of decent free Lisp compilers played
  a part in this decision.} Stallman decided to write a Lisp interpreter and
editor primitives like display handling in C, while writing as many higher level
functions as possible in Lisp.  The dialect he designed and implemented is
called \el{}, or elisp for short\footnote{Note though, that there once was an
  unrelated dialect of the name elisp.}.  In 1984 Stallman wrote what is now
known as GNU Emacs\cite{emacs-first-release}. Since then, \el{} has grown and
changed a lot.

While Emacs is primarily a text editor, it achieves its extensibilty by
being/providing a virtual Lisp Machine.  So far only some experimental features
exist to incorporate shared objects into a running instance of Emacs, so the
only ways to add features is to modify the C code base, which requires
recompilation, or by loading \el{} code.  All C functions which users may need
are exported to Lisp, and are largely indistinguishable from Lisp functions,
macros or special forms.  This extensibility has made Emacs one of the most
powerful editors available.  For the rest of this thesis, the editing
capabilities of Emacs are rather unimportant.  The thesis will concentrate more
on the Lisp Machine part of Emacs.

The capabilities of \el{} have drastically improved over the last years.  Until
Emacs 24.1 \el{} only featured dynamic scope\cite{Emacs-Lexical}.\footnote{See
  \cite{CLTL2}
  (\url{http://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node43.html})for an
  explanation of why ``dynamic scope'' is a misnomer, yet still useful as a
  term.  While the differences in scope and extent are interesting, they are not
  relevant to this thesis.}  In the version of Emacs which will probably be
named 25.1 Emacs will also feature watered down \cl{} style multimethods.  As
these methods were used for the code in this thesis, said code requires at least
a pretest version of Emacs\cite{emacs-pretest}.

\chapter{A brief history of Lisp}
\label{sec:lisp-hist}

Pinpointing Lisps exact moment of birth is rather difficult, as it is often the
case with Ideas which take some time to develop.  John McCarthy published a
paper in 1960 on the language\cite{rec-fun-sym-expr} in which some ideas,
notation among others, from Alonzo Church’s $\lambda$-calculus are used.

The gist of the paper is that McCarthy devised a theoretic system to represent
functions in programs.  This was originally meant as a theoretic foundation,
yet, as McCarthy writes in his retrospective notes on Lisp history
\cite{lisp-hist}: “S.R. Russell noticed that eval could serve as an interpreter
for LISP, promptly hand coded it, and we now had a programming language with an
interpreter.”

While it may have been an accident that Lisp got an implementation, thus
becoming an actual programming language at the time that it did, the foundation
was laid down at that time, so it could have happened at any later point.

As Lisp introduced several ideas which were new to programming, resulting in
high expressive power, it quickly became popular in some circles, especially the
artificial intelligence community, of which McCarthy war a part.  This was
probably simply because Lisp was more powerful than any other language of the
time, even though it was very slow.  It was slow compared to other languages of
the time, namely machine language/assembly and FORTRAN.  It was also slow simply
because compiler technology was not nearly as advanced as it is today.

What makes Lisp special is discussed in greater detail in section
\ref{sec:lisp-special}. 

\begin{comment}
  Paul Graham nicely listed 9 particularly important ideas: \cite{pg-lisp-diff}

  \begin{description}
  \item [Conditionals] A conditional is an if-then-else construct. We take these
    for granted now. They were invented by McCarthy in the course of developing
    Lisp. (Fortran at that time only had a conditional goto, closely based on
    the branch instruction in the underlying hardware.) McCarthy, who was on the
    Algol committee, got conditionals into Algol, whence they spread to most
    other languages.
  \item[A function type] In Lisp, functions are first class objects-- they're a
    data type just like integers, strings, etc, and have a literal
    representation, can be stored in variables, can be passed as arguments, and
    so on.
  \item[Recursion] Recursion existed as a mathematical concept before Lisp of
    course, but Lisp was the first programming language to support it. (It's
    arguably implicit in making functions first class objects.)
  \item[A new concept of variables] In Lisp, all variables are effectively
    pointers. Values are what have types, not variables, and assigning or
    binding variables means copying pointers, not what they point to.
  \item[Garbage Collection]
  \item[Programs composed of expressions] Lisp programs are trees of
    expressions, each of which returns a value. (In some Lisps expressions can
    return multiple values.) This is in contrast to Fortran and most succeeding
    languages, which distinguish between expressions and statements.

    It was natural to have this distinction in Fortran because (not surprisingly
    in a language where the input format was punched cards) the language was
    line-oriented. You could not nest statements. And so while you needed
    expressions for math to work, there was no point in making anything else
    return a value, because there could not be anything waiting for it.

    This limitation went away with the arrival of block-structured languages,
    but by then it was too late. The distinction between expressions and
    statements was entrenched. It spread from Fortran into Algol and thence to
    both their descendants.

    When a language is made entirely of expressions, you can compose expressions
    however you want. You can say either (using Arc syntax)

  \begin{lstlisting}[style=lispinline]
    (if foo (= x 1) (= x 2))
  \end{lstlisting}

  or

  \begin{lstlisting}[style=lispinline]
    (= x (if foo 1 2))
  \end{lstlisting}

\item[A symbol type] Symbols differ from strings in that you can test equality
  by comparing a pointer.
\item[A notation for code] using trees of symbols.
\item[The whole language always available] There is no real distinction between
  read-time, compile-time, and runtime. You can compile or run code while
  reading, read or run code while compiling, and read or compile code at
  runtime.

  Running code at read-time lets users reprogram Lisp's syntax; running code at
  compile-time is the basis of macros; compiling at runtime is the basis of
  Lisp's use as an extension language in programs like Emacs; and reading at
  runtime enables programs to communicate using s-expressions, an idea recently
  reinvented as XML.
\end{description}

Given only the original paper, it is unclear whether or not functions had a
separate data type, as Graham implies.  The paper seems to suggest that a
function is simply a list which happens to be called or evaluated.  This is
still possible in at least some Lisps, \el{} among them.  \footnote{Note that
  this does not mean that a function is necessarily merely a list of a
  particular form, or that any guarantees on the form are given.}  The point
Graham makes stays though: it was possible to create functions at runtime and
pass them around as any other value.
\end{comment}

Lisp was originally supposed to adopt a different syntax, especially for
function calls and definitions.  McCarthy even used this syntax, called
M-expressions, in his original paper \cite{rec-fun-sym-expr}.  They were to be
translated into S-expressions (short for Symbolic expressions).  While in the
original paper the syntactic representation of S-expressions and lists was
slightly different\footnote{McCarthy originally allowed spaces in atoms,
  i.e. symbol names, and separated list elements with a comma.  Today spaces are
  used to delimit elements.}, they essentially had their current form, namely
consisting of symbols and lists, using a prefix scheme, i.e. having the operator
as the first element of a list.

McCarthy himself used the term S-expression for symbols, while today most Lisp
programmers use the term S-expression, or sexp for short, to mean any string of
characters which may be read by a Lisp implementation.  The latter meaning will
be used in this thesis from now on.

This proposed translation was not merely a syntactic, let alone cosmetic change.
Compilers and interpreters in general need some form of source representation
which is above the character level of the source code which they take as input.
This is typically called an abstract syntax tree (AST)\footnote{The exact
  differences and relationships between ASTs, concrete syntax trees and the like
  are beyond the scope of this thesis.}.  Lisp, being a dynamically typed
language, allows the syntax tree to be particularly simple.  While a tree in a
statically typed language may need structures to differentiate between a
function call (which has a name and one or more arguments), and a number
literal, in Lisp one can simply use dynamic typing.  This way, numbers, strings,
symbols etc. can be put directly in place, while nested lists provide the tree
structure needed.

As Lisp programs can be represented with data structures which Lisp provides,
higher-order programs became possible quite early in the history of computers.
Lisps syntax and its relationship to metaprogramming is discussed in further
detail in section \ref{sec:lisp-special}.

\chapter{What makes Lisp special}
\label{sec:lisp-special}

As outlined at the end of section \ref{sec:lisp-hist}, Lisp code can be
represented in its own data structures.  This sets it apart from most (if not
all) mainstream languages in use today. As this is vital to the rest of this
thesis, it is discussed in detail here.

As an example, we will transform a simple algebraic expression.  The simple
expression \(a + b \cdot c\) can be put into a tree form (figure
\ref{fig:simple-tree}).  Note that in tree form, parentheses are no longer
needed to group terms.  Also, all precedence becomes explicit.

\begin{figure}[h]
  \centering
  \begin{tikzpicture} %[every node/.style = {shape=circle, draw}]
    \node [op] {+} child { node [arg] {a} } child { node [op] {\times}
      child { node [arg] {b} } child { node [arg] {c} } };
  \end{tikzpicture}
  
  \caption{Tree form of an algebraic expression}
  \label{fig:simple-tree}
\end{figure}

Alternatively, given lists of arbitrary length (represented by surrounding
parenthesis), symbols and dynamic typing, the same tree may also be represented
like this:

% Given a list notation as used in Lisp, i.e. parentheses and spaces which delimit
% elements, together with prefix notation, it may as well look like this:

\begin{lstlisting}[style=lispinline]
  (+ a (* b c))
\end{lstlisting}

Given that Lisp syntax is given as nested lists, symbols and prefix notation, it
becomes apparent that Lisp only has (linear) syntax for ASTs.  This means that
programmers do not enter syntactic forms, but directly enter the AST for their
programs.

This may put off some programmers as unaesthetic\footnote{Many non-lispers claim
  that Lisps syntax---or lack thereof---is difficult to read, yet I and many
  other Lisp programmers disagree.  Once a programmer has become accustomed to
  this kind of source code, it can become quite appealing, and the parenthesis
  are not as intrusive to the mind as many initially suspect.}.  While it is
difficult to meaningfully argue over such subjective topics, there are technical
advantages to this approach, which come in at least four categories, each of
which are discussed in more detail in the following subsections: macros, sexp
communication, editing tools, customizable syntax.

\section{Macros}
\label{subsec:macros}

As programs can be represented by data structures which are accessible to the
user of the language, an implementation may provide hooks which allow the user
to add transformation routines.  Such a routine may take a source tree, which
has been read, but not evaluated, and return such a source tree, which is
evaluated instead of the invocation of the transformer itself.  In lisp, such
transformers are called macros.  A macro is a procedure, written in Lisp, which
operates on Lisp source code.  The result of calling a macro procedure is called
the expansion of said macro.  Listing \ref{code:increment} is taken from the
``GNU Emacs Lisp Reference Manual''.\footnote{Note that this definition has some
  (fixable) problems, which make it unsuitable for production work.}

\begin{lstlisting}[style=lispcode,caption={Increment as a
      macro.},label={code:increment}]
  (defmacro inc (var)
        (list 'setq var (list '1+ var)))
\end{lstlisting}

This macro is called with \texttt{(inc x)} where \sym{x} is an already existing
variable.  Inside the macro procedure \sym{val} is \emph{not} bound to the value
which \sym{x} will hold at runtime, but with the \emph{symbol} \sym{x}.  This
makes it possible to perform macro expansion at runtime.  The procedure returns
a list, which is evaluated at runtime.  As the first element of this list is the
symbol \sym{setq}, it sets a variable to a value.  The code which produces the
expansion, as well the expansion itself may be arbitrarily complex.  There is a
lot more to write about how to use macros in practice.  The ``GNU Emacs Lisp
Reference Manual'' has a section devoted to macros in \el, and Paul Grahams book
``On Lisp'' \cite{on-lisp} features an excellent chapter on macros in \cl{}.

A more sophisticated macro can be found in the source code to this thesis (see
listing \ref{code:make-accessors}, which generates getters and setters for a
class).  The arguments to the macro are a symbol which denotes the class for
which accessors shall be created, and an optional second symbol which denotes a
prefix for all accessors.

\begin{lstlisting}[style=lispcode,caption={Create accessors for all data members
  of a given class.},label={code:make-accessors}]
(defmacro el-reader//make-public-accessors (class &optional prefix)
    (cons 'progn
          (seq-map
           (lambda (e)
             `(progn
                (defun ,(intern (s-concat (if prefix (symbol-name prefix)
                                            "")
                                          (symbol-name e)))
                    (obj)
                  ,(s-concat "Extract the element " (symbol-name e)
                             " from OBJ. ")
                  (slot-value obj ',e))
                (cl-defmethod (setf ,(intern (s-concat
                                              (if prefix
                                                  (symbol-name prefix)
                                                "")
                                              (symbol-name e))))
                    (new-elt (obj el-reader/readtable))
                  (setf (slot-value obj ',e) new-elt))))
           (seq-map #'eieio-slot-descriptor-name
                    (eieio-class-slots class)))))
\end{lstlisting}

For every data member \sym{memb}, prefix \sym{prefix/} in the class
\sym{klass}, the code in listing \ref{code:data-member} has to be generated.

\begin{lstlisting}[style=lispcode,caption={Getter and Setter for a member called
  \sym{member}.},label={code:data-member}]
(defun prefix/memb (obj)
  "Extract the element invalid-chars from OBJ. "
  (slot-value obj (quote invalid-chars)))
(cl-defmethod (setf prefix/memb)
    (new-elt (obj klass))
  (setf (slot-value obj (quote memb)) new-elt))
\end{lstlisting}

This code inspects the slots (i.e. member variables) of the class given in the
first argument with the function \fun{eieio-class-slots} which returns a list of
slot descriptors.  The function \fun{eieio-slot-descriptor-name} in turn returns
the name of the given slot, which is done for each slot (with \fun{seq-map}).
For each slot name a getter (\fun{defun}) and setter (\fun{cl-defmethod}) is
created.  Note that the macro itself does not create these functions.  The macro
returns code which---when run---creates said functions.  The alternative to this
macro would have been to write getters and setters for every data member in a
class manually.\footnote{For this program, the macro was used only once.  The
  expansion is almost 80 lines long, if properly formatted.}  This is not only a
menial task not worthy of a self respecting programmer, but also error prone and
highly unmaintainable.  If for instance the desired prefix changes, every getter
and every setter has to be inspected and changed.

\section{Communication via sexps}
\label{subsec:sexp-communication}

When a given program needs to save or read data from a file, a stream, or some
other medium, some form of structure is needed.  The simplest case is a binary
format, yet these schemes often suffer from lack of extensibility and
debugability.  If a text based scheme is called for, some sort of syntax is
needed.  In the \unix{} culture plaintext files with assignments using the
\texttt{=} is and was often used.  Programs on \windows{} often used INI files.
Both cultures seem to tend towards XML.  

XML and sexps are quite similar.  Both describe a tree shaped structure, without
specifying what labels are permitted.  XML seems to focus on cases where there
is a lot of text and little markup (hence making it quite suitable for the web),
while sexps are well suited for cases with lots of markup and little text.  One
could say that sexps focus more on symbols, while XML focuses on strings.

While it is possible to describe both a document and a program with XML or with
sexps, it quickly becomes ugly to describe a document with sexps because text
must be escaped.  Likewise, describing programs in XML is very verbose and ugly,
as can be seen by looking at an ant file.

Both XML and sexps serve the purpose of providing a linear syntax for data
objects.  A syntax which may not only be read by a program, but also which may
be written, as data objects may be printed in XML or sexps notation.

The obvious benefit of using sexps to share data between processes for a Lisp
programmer is rather obvious: the syntax is the same as the language itself and
both readers and printers are available by definition.  At least in \cl{} both
are customizable, which allows for new syntax for new data types.  Often new
syntax is not needed, as printing can produce an expression which can be
transformed at runtime.  A hash table might be printed like this:
\begin{lstlisting}[style=lispinline]
(hash-table size 65 test eql rehash-size 1.5
            rehash-threshold 0.8
            data (:foo "FOO!" :bar "BAR!"))
\end{lstlisting}

In such an example the mere reading of an expression will not yield a hash
table.  Yet interpreting such a structure gives enough details on how to
construct the table in memory, similar as would be done using XML.

\section{Editing Tools}
\label{subsec:edit-tools}

While editing any kind of language, one may encounter intermediate states which
are invalid.  While typing ``<a href=http://example.com>link</a>'' in an XML
document, the person typing this will break the structure of the file in several
ways:  ``<'' alone is not valid in XML.  ``<a'' too, is invalid.  The same
problem exists for sexps: ``(a ((href . "http://example.com")) "link")'' is an
sexps which has roughly the same structure as the previous XML example.  Here,
unbalanced parentheses cause the text to become invalid syntax, i.e. no tree can
be constructed from it.

For \emacs{} there are at least two tools which address this problem:
paredit\cite{paredit} and lispy\cite{lispy}.  Both tools provide alternative
editing commands which ensure a valid tree:  if an open paren is inserted, a
closing paren is also inserted.  A list may be expanded to include the next
element, or eject the last element from the list (thus always keeping the tree
intact).  These tools also offer commands which raise a whole expression (of
arbitrary size) up one level in a tree, deleting one level.  An example may be
used to illustrate:

\begin{lstlisting}[style=lispinline]
(if (some-predicate arg1 arg2 and some more really
                    complex code!)
    simple-value)
\end{lstlisting}

Given this code, a programmer might discover that the whole if expression is not
needed, and that \sym{simple-value} should always be used.  Given very few
commands, both paredit and lispy can \emph{raise} the token \sym{simple-value}
to produce a new tree:

\begin{lstlisting}[style=lispinline]
simple-value
\end{lstlisting}

Note that this is done (somewhat) atomically: at no point is there an opening or
closing paren which distorts the syntax tree.

While such tools may not be impossible for other languages, sexps (and XML
probably too, yet the author is not aware of such tools for XML) make this much
easier than other languages.\footnote{To show how ``simple'' this can be, one
  can simply take a look at the length of the source code of such tools: the
  lispy version I use at the time of writing consists of 12 files for several
  languages, and less than 10,000 lines of \el{} code (including comments etc).
  While this is still quite a lot, it probably would be a lot more for languages
  with more ``traditional'' syntax, let alone for languages with undecidable
  grammars like C++.}

\section{Customizable Syntax}
\label{subsec:custom-syntax}

As Lisp syntax is merely syntax for an AST, i.e. data, this syntax can be
customized to include new data types, or to redefine existing syntactic
constructs.  It is important to note that this is not true of Lisps in general,
only that it is possible for a Lisp to exhibit this kind of behavior.  \cl{}
features a customizable reader \el{} does not, which is why this thesis
addresses the issue for \emacs{}.

Not many users of \cl{} seem to use this set of features, as free and good
introductory material on the topic is quite lacking on the web, although
Graham’s On Lisp \cite{on-lisp} does feature a short chapter on read
macros.\todo{Add a ref to the section which details the lisp reader.}

\chapter{Lisp Basics}
\label{subsec:lisp-basics}

This section is only intended as a short recap of what Lisp syntax is, and how
it relates to the reader.  For more details, a Lisp textbook is more
appropriate.  A good reference for \el{} is found at \cite{elisp-reference}.

Lisp syntax never directly describes control flow, function definitions, or
other actions, but merely data.  If the described data consists of lists and
symbols, it will later on be treated as code, which can be compiled and
executed.\todo{Possibly show some Lisp examples.}

Such data structures can represent code by having a list with an ``action'',
which may be a special form, a macro or a function, as its first element.  Any
further elements are arguments to said operator.

As an example, here is some code which performs a variable binding with
\fun{let} (which is a special form), an assignment with \fun{setf} (a macro)
and a function call to \fun{message}.

\begin{lstlisting}[style=lispinline]
  (let ((var 5)) (setf var "Hello") (message "%s" var))
\end{lstlisting}

When Lisp source code is processed, it goes through three distinct stages:
reading, macro expansion (optionally this can also be a compile phase), and
evaluation (which can be the execution of compiled code).

The first stage is somewhat unique to Lisp---most languages only have this as an
implementation detail in the compiler or interpreter.

\section{Important Lisp Data Types}
\label{subsec:important-types}

A few Lisp data types are of particular importance, both because they are
relatively rare in other languages, but also because they are very widespread in
Lisp code, i.e. the reader often creates them.

Every Lisp dialect the author is aware of provides at least the following:

\subsection{Symbols}
\label{subsubsec:symbols}

The symbol is a type which represents a name, often together with places for
values and/or functions.  The latter depend on the Lisp dialect.  An important
property of symbols is that fast lookup is supported, and that symbols are
interned.  This means that each symbol which is read, which has the same name,
returns the same Lisp object.\footnote{This is, in effect, a singleton.}

In \el{}, which is the Lisp under consideration for this thesis, a symbol has
the following attributes:

\begin{description}
\item[{Name}] A (typically hashed) name for the symbol.  This may be retrieved
  as a string at any time.
\item[{Value}] This is the value of the symbol.  It may be retrieved by a call
  to \fun{symbol-value} or by simply appearing in a program (macros or special
  forms may treat symbols differently).
\item[{Function}] This cell is looked up if the symbol is the first element of a
  list which is evaluated (more on this later).  Alternatively, a call to
  \fun{symbol-function} returns the function to which it points (if any).
\item[{Property List}] A symbol may also have a Property List, or plist for
  short, which is a mapping from a key (mostly a symbol) to a value.  This is
  intended as a mechanism to store arbitrary metadata in a symbol.
\end{description}

A fifth attribute exists, which is not visible from Lisp code.  Symbols are
placed into so called ``obarrays'', which are similar to hashtables, but are
specialized to symbols (i.e. no other objects can be stored in them).  To
support fast lookup and low memory usage, each symbol contains a pointer to the
next symbol in the same bucket of the obarray.  For this reason a symbol may
only be interned in one obarray.  Because of this limitation it is not possible
(at the time) to implement \cl{} compatible packages for \emacs{} (not to be
confused with the packages provided in \fun{package.el}, which are installable
units).

\subsubsection{Read Syntax}
\label{subsubsec:symbol-syntax}

The read syntax for a symbol is any token of text which is not also a valid
number, does not contain any unescaped terminating macro characters and does not
start with an unescaped macro character.

Thus \sym{foo}, \sym{1+}, \sym{contains?} and \sym{set!} are valid symbols.
\sym{+1} is not, as it is the positive number one.  \sym{\textbackslash{}+1} on
the other hand is a valid symbol, as the \sym{+} sign is escaped.  Its name is
``+1'' (i.e. the escape character is only part of the read syntax, not of the
outcome). 

\subsection{List}
\label{subsubsec:list}

In Lisp parlance, when a list is mentioned, it is almost always a singly linked
list.  While by far not the only compound data structure\footnote{Strictly
  speaking, lists by themselves to not exist: there are only cons-cells, yet
  this nuance is not very important for the current discussion.}, it is a very
important one.

Not only is there syntax for lists; together with the symbol, the list is used
as the prime representation for code.  Lists are made up of cons cells, which
are ordered pairs of Lisp objects.  They can be constructed at runtime with a
call to \fun{cons}, passing the two objects as arguments.  Two additional
operations fetch the contents and serve as setf-able places: \fun{car} and
\fun{cdr}.  The former fetches the first element of the cons, the latter the
second.  Cons cells can be linked.  By convention, the cdr of a cons points to
the next cons, or \sym{nil}, if at the end of a list.  This type of structure is
called a proper list.  A chain of conses which do not end in a cons with a cdr
of \sym{nil} is called an improper list.

\subsubsection{Read Syntax}
\label{subsubsec:list-syntax}

Cons cells, proper and improper lists have read syntax to create them at
read-time:

\begin{description}
\item[cons] A single cons may be notated as a ``dotted-pair'': \texttt{(car
    . cdr)}

  Here a new cons is created which has a car of \sym{car} and a cdr of
  \sym{cdr}.
\item[proper list] A proper list is notated with whitespace separated elements
  surrounded by parentheses: \texttt{(foo bar)}

  This is equivalent to \texttt{(foo . (bar . nil))}
\item[improper list] An improper list looks like a proper list, yet uses
  embedded dotted pair syntax at its end: \texttt{(foo bar . spam)} is
  equivalent to \texttt{(foo . (bar . spam))}.
\end{description}

\subsection{Other Types}
\label{subsec:other-types}

Most other types are rather unspectacular and depend on the dialect under
consideration.  Practically all Lisps provide strings, \el{} even provides an
alternate notation which provides text properties: \texttt{\#("foo" 0 1 (escapedp
  t))}.  This represents a string ``foo'', with the property \sym{'escaped} and
the corresponding value \sym{t} on the first letter.

Numbers are also often a little different than in mainstream languages.  Both
\cl{} and scheme provide exact fractions.  \cl{} and \el{} provide read syntax
for integers in several bases: \texttt{\#b1111} \texttt{\#o17} \texttt{\#xF} and
\texttt{15} all represent the number 15 in base 10.  This notation is the same
in \cl{} and \el{}.  This notation has a certain air of elegance to it as soon
as one realizes that \texttt{\#} is a dispatching macro character\todo{Add a
  section on dispatching macro characters and reference it.}.  This means that
\texttt{\#b}, \texttt{\#o} and \texttt{\#x} may be implemented as read macros.

\chapter{Motivation}
\label{sec:motivation}
Users of other Lisp dialects, especially of \cl{}, have enjoyed the possibility
to modify the syntax they use to write programs for a long time.  This
possibility provides a huge benefit in the course of evolving a language, as
well as implementing readers for custom languages.  Macros---which are expanded
at compile-time---provide a very powerful mechanism for code transformation
(i.e. ASTs to ASTs).  These allow to control the order of evaluation of forms
within the macro, as well as the opportunity to transform them, yet sometimes
even this kind of power is not quite enough, as the macro call must still
consist of valid s-expressions.

A very simple case is the addition of syntax for data structures, since this is
what the reader is there for anyway: transforming characters into data
structures.  Most modern programming languages provide some syntax to enter hash
tables.  Take for instance python, where the keys and values may be specified
between curly braces:

% \begin{minted}[]{python}
% {"foo": "bar", "five": 5}
% \end{minted}

\begin{lstlisting}[style=pythoncode]
{"foo": "bar", "five": 5}
\end{lstlisting}

When entered into a python interpreter, this expression returns a hash table (or
Dictionary in Python terminology).

Clojure, a rather recent addition to the Lisp family of languages also features
a similar syntax:

% \begin{minted}[]{clojure}
% {"foo" "bar" "five" 5}
% \end{minted}

\begin{lstlisting}[style=lispinline]
{"foo" "bar" "five" 5}
\end{lstlisting}

This also returns a mapping from keys to values.

Unfortunately, neither \cl{} nor \el{} feature such (concise)
syntax\footnote{\el{} has read (and even print) syntax for hash tables, yet is
  is rather ugly.  The same table looks like this: \#s(hash-table size 65 test
  eql rehash-size 1.5 rehash-threshold 0.8 data ("foo" "bar" "five" 5))}.  \cl{}
users may create such a syntax themselves, yet \el{} users never had this
possibility.

In the absence of read macros, one possible shortcut is to simply define a
function to do so; consider the function \fun{ht} in listing \ref{code:cl-ht}
from the source code of this thesis, ported to \cl{}.

% \begin{listing}[h]
% \caption{Creating a hash table.}
% \label{mint:cl-ht}
% \begin{clcode}
% (defun ht (&rest args)
%   "Create and return a hashtable.

% Keys and values are given alternating in args."
%   (let ((h (make-hash-table)))
%     (loop for (key value) on args by #'cddr
%        do (if (and key value)
%               (setf (gethash key h) value)
%               (error "Odd number of arguments passed")))
%     h))
% \end{clcode}
% \end{listing}

\begin{lstlisting}[style=lispcode,caption={Creating a hash
  table.},label={code:cl-ht}]
(defun ht (&rest args)
  "Create and return a hashtable.

Keys and values are given alternating in args."
  (let ((h (make-hash-table)))
    (loop for (key value) on args by #'cddr
       do (if (and key value)
              (setf (gethash key h) value)
              (error "Odd number of arguments passed")))
    h))
\end{lstlisting}
This may be used as

% \begin{clcode}
% (ht "foo" "bar" "five" 5)
% \end{clcode}

\begin{lstlisting}[style=lispinline]
(ht "foo" "bar" "five" 5)
\end{lstlisting}


instead of the more cumbersome and repetitive code shown in listing
\ref{code:cl-canon-ht}.

% \begin{listing}[h]
% \begin{clcode}
% (let ((h (make-hash-table)))
%   (prog1 h
%     (setf (gethash "foo" h) "bar")
%     (setf (gethash "five" h) 5)))
% \end{clcode}
% \caption{Canonical way to create a hash table.}
% \label{mint:cl-canon-ht}
% \end{listing}

\begin{lstlisting}[style=lispcode,caption={Canonical way to create a hash
  table.},label={code:cl-canon-ht}]
(let ((h (make-hash-table)))
  (prog1 h
    (setf (gethash "foo" h) "bar")
    (setf (gethash "five" h) 5)))
\end{lstlisting}

To further shorten and clarify the creation of hash tables, \cl{} users may use
a read macro. Listing \ref{code:cl-hash-reader} shows how this may be done
(assuming \fun{ht} has been defined as in listing \ref{code:cl-ht}).
\footnote{The details of this code are not of particular importance, merely that
  it is possible, and quite short.}

\begin{lstlisting}[style=lispcode,caption={A \cl{} read macro to read hash
  tables}.,label={code:cl-hash-reader}]
(set-macro-character #\} (get-macro-character #\)))

(set-macro-character
 #\{
 (lambda (stream char)
   (declare (ignore char))
   (let ((k-v (read-delimited-list #\} stream t)))
     (if (oddp (length k-v))
         (error "Invalid syntax: {}")
         `(ht ,@k-v)))))
\end{lstlisting}

Now the \cl{} reader reads ``\{\ldots{}\}'' constructs in a similar fashion as
the Clojure reader does.

Given \elr{}, i.e. the code from this thesis, the code in listing
\ref{code:el-hash-reader} may be used in \el{} to produce the same effect.

\begin{lstlisting}[style=lispcode,caption={An equivalent read macro using
  \elr{}.}, label={code:el-hash-reader}]
(defun ht (&rest args)
  "Create and return a hashtable.

Keys and values are given alternating in args."
  (let ((h (make-hash-table)))
    (cl-loop for (key value) on args by #'cddr
             do (if (and key value) (puthash key value h)
                  (error "Odd number of arguments passed")))
    h))

(el-reader/set-macro-character
 ?\} (car (el-reader/get-macro-character ?\))))

(el-reader/set-macro-character
 ?\{
 (lambda (stream _char)
   (cl-values
    (let ((k-v (el-reader/read-delimited-list ?\} stream t)))
      (if (= (mod (length k-v) 2) 1)
          (error "Invalid syntax: {}")
        `(el-reader//ht ,@k-v))))))
\end{lstlisting}

Note the similarity of the API.  The prefixes have been put in place, as \el{}
provides no packaging facilities.\footnote{Should Emacs change the internal
  representation of symbols, packaging may be possible, given this reader, yet
  is beyond the scope of this thesis.}

A more sophisticated use case might be to provide read syntax for regular
expressions---regexps for short.  In \el{} regexps are notoriously ugly to enter
and read, because they are opaque strings, which are passed to a function, which
parses and compiles them at runtime.  This means that many constructs must be
escaped multiple times, which makes the strings difficult to read and write.  A
particular notorious offender is the regular expression which matches a single
backslash; in Clojure one may write \texttt{\#"\textbackslash\textbackslash"},
\el{} users are forced to write the much more cumbersome
\texttt{"\textbackslash\textbackslash\textbackslash\textbackslash"}.  Here again
Clojure shows a nice way to handle the issue: by providing syntax for them.

While Clojure provides more syntax than \el{} does, and more than \cl{} does out
of the box, it provides no way for users to add their own constructs.

Finally, it is also possible to define non-standard evaluation semantics, as the
code for read macros is run at read time.  This means that calculations may be
performed at read time, which---for most code---is effectively compile-time.

An example for this is something similar to rubys \texttt{\%w} construct.  It
reads a list of tokens, converts them to strings and makes an array out of
them.  

\begin{lstlisting}[style=rubyinline]
%w(foo bar spam and eggs) 
=> ["foo", "bar", "spam", "and", "eggs"]
\end{lstlisting}
\todo{Possibly fix the code box.}

If one is willing to ignore that ruby is very flexible about the delimiters, one
might define something similar to \texttt{\#w(...)} in Lisp as in listing
\ref{code:elr-ruby-words}.

\begin{lstlisting}[style=lispcode,caption={A read macro for rubys word
  syntax.}, label={code:elr-ruby-words}]
(defvar *my-read-stuff/word-seq-types*
  {'cons #'list 
   'vector #'vector})

(defun my-read-stuff/read-words (stream char _num)
   (let ((words (el-reader/read stream t nil t)))
     (if (not (seqp words))
         (error "Invalid syntax: #w")
       (cl-values
        `(quote
          ,(apply
            (gethash (type-of words)
                     *my-read-stuff/word-seq-types*)
            (seq-map (lambda (s)
                       (if (not (symbolp s))
                           (error "Invalid syntax: #w")
                         (symbol-name s)))
                     words)))))))

(el-reader/set-dispatch-macro-character
 ?# ?w
 #'my-read-stuff/read-words)
\end{lstlisting}

While this version uses different delimiters for different types of return value
(parentheses form a list, square brackets form a vector), it can only use
certain delimiters, namely those which have read syntax for a sequential data
structure.  On the other hand it is extensible in the types it provides, and
most importantly forms the structure at read-time.  This may be of some worth
for large constants.

Here is how it is used:

\begin{lstlisting}[style=rubyinline]
#w(foo bar spam eggs) => ("foo" "bar" "spam" "eggs")
#w[foo bar spam eggs] => ["foo" "bar" "spam" "eggs"]
\end{lstlisting}

\chapter{Replacing Emacs’ built-in reader}
\label{sec:repl-reader}

When contemplating the replacement of such a critical and internal part of the
implementation of a programming language, one must find a way to do so.  The
obvious way is to replace the C code within \emacs{} itself.  The obvious
advantage to this approach is speed and good integration.  The drawback is that
programming in C is rather slow going, and that C and \el{} have very different
data and execution models.  Another problem is that this makes distribution more
cumbersome.  The changes needed for this approach really are modifications of
existing code, not mere additions.  Applying these changes would require the
user to patch and recompile Emacs.  On the other hand, if these changes got
included into \emacs{} by its maintainers, distribution would be automatic.

Another possibility is to implement the reader in \el.  This not only has the
advantage of easing development, by virtue of \el{} being a more powerful
language than C, and not having to switch between different data and execution
models.  It also makes it possible to distribute the resulting reader in an
optional package, so every user may independently choose whether or not to use
it.

The second approach has one problem: the original reader must be replaced at
runtime.  This is possible due to the dynamic nature of \el.  A function may not
only be replaced wholesale, as is possible in many languages (such as python),
but can also be ``advised''.  This is a feature which has been present in many
Lisp dialects in the past, and has recently seen some popularity under the name
of ``Aspect oriented programming''

\emacs{} offers many different ways to add code to a function, all documented in
the manual in section 12.11 ``Advising Emacs Lisp
Functions''\cite{elisp-reference}.  In order to replace the reader (which
consists of only one function: \fun{read} and a few variables) it is sufficient
to place \sym{:around} advice onto the function in question.  This has the
effect that all calls to \fun{read} will be redirected to a different, user
supplied function with all arguments, plus the original function as an extra
argument.

This makes it possible to check whether \elr{} shall be used or not, and
redirect to the original function instead.  Also, it makes it possible for
\elr{} to reuse the original reader, where appropriate\footnote{Note that this
  was done only for performance reasons.  Also, nested structures can not in
  general be reused, as the original reader in \emacs{} is not aware of macro
  chars and the like.  If the code for reading lists had been reused, ``(foo
  bar)'' would still read correctly, yet ``(foo \{:bar :spam\})'' would fail, as
  the built-in reader does not know what to do about curly braces.}.

Given this possibility, replacing the built-in reader is a matter of a few lines
of \el{} code, as can be seen in listing \ref{code:replace-reader}.

\begin{lstlisting}[style=lispcode,caption={Replacing the built-in
    reader},label={code:replace-reader}]
(define-advice read (:around (oldfun &optional stream)
                             el-reader//replace-read)
  (if (and use-el-reader (not el-reader-bytecode))
      (el-reader/read stream)
    (funcall oldfun stream)))
\end{lstlisting}

\section{Compatibility}
\label{subsec:compat}

When replacing such a critical part of a language, it is important to maintain
compatibility.  For this, several criteria must be met:

\begin{enumerate}
\item Previously accepted code must be accepted by the new system.
\item Previously accepted code must have the same meaning in the new system.
\end{enumerate}

Both criteria may seem obvious, yet they apply both to syntax and to a function
call, namely to \Read{}.

To achieve this, it is necessary to take a look at the signatures of \Read{}
both in \el{} as in \cl{}, as \elr{} takes a lot of inspiration from \cl{}.  In
\el{} read takes 0 or 1 arguments, where stream is either:
\begin{description}
\item[nil:] the value of \sym{standard-input} (defaults to \sym{t}) is used.
\item[a buffer:] begin at point and advance it.
\item[a marker:] read from where it points and advance it.
\item[a function:] called without arguments to retrieve a character, called with
  one argument to unread a char.
\item[a string:] starts at the beginning, does not change its argument
\item[\sym{t}:] read a line of text either from the minibuffer (very Emacs
  specific), or from standard input, if used in batch mode
\end{description}

\begin{lstlisting}[style=lispinline]
(read &optional STREAM)
\end{lstlisting}

In \cl{} \Read{} as the following signature:

\begin{lstlisting}[style=lispinline]
(read &optional (stream *standard-input*) (eof-error-p t)
      (eof-value nil) (recursive-p nil))
\end{lstlisting}

As in \el{} stream may be called without arguments, yet if exactly one is given,
it refers to a stream.  All extra arguments are also optional, and their default
behaviour is---as far as it applies to \emacs{}, identical.

The signature chosen for \elr{} is a little more complex, yet is fully
compatible with \emacs{}’ \Read{} and reasonably compatible with \cl{}:

\begin{lstlisting}[style=lispinline]
(el-reader/read &optional input-stream (eof-error-p t)
                eof-value recursive-p keys)
\end{lstlisting}

The last argument needs some explaining.  Unfortunately, \el{} lacks several
features which are present in \cl{}, hence the authors of \cl{}’s \Read{} took
for granted.  Among these features is the possibility to have a function return
a number of values different than one (i.e. more than one, or even none at all)
without forcing the caller to know or care about the fact.  In \cl{} the first
value returned by a function is called the primary value.  This value can be
used as if the called function merely returned one value.  Should any other
values be of interest, they must be explicitly bound by
\sym{multiple-value-bind} or similar operators.  The multiple values facility of
\cl{} also allows for no values to be present.  In such a case, the primary
value (if bound) is \sym{nil}, yet the caller \emph{may} check for the number of
returned arguments.  As \el{} does not support this mechanism, \elr{} passes an
additional argument named \sym{keys} to switch between returning exactly one
value, and returning a (possibly empty) list of values.  This is done, as it is
possible for a read macro to return no value.  This is done for comments.  For
this reason, read macros must always wrap their return value in \fun{list}, or
\fun{cl-values} (which---at the time of writing---is an alias for \fun{list}).

Note that the keys argument never has to be given by the user.  It is given only
in one two places, which is in \fun{el-reader/read} itself, i.e. in a
self-recursive call, and in the function \fun{el-reader/read-delimited-list}.
Nevertheless, the user must always return a list of values in read macros, which
is a shame, as it departs from the way it is done in \cl{}.

There are other features which are present in \cl{} but not in \el{}, yet none
of them are so critical (and difficult to retrofit) as multiple values.  Some
other features can be emulated at various degrees of awkwardness, such as having
non-nil default values for optional arguments.  These can be used with
\fun{cl-defun}, and have been used in the code for \elr{}.

Other features have only started to appear in \emacsv{25}, such as multiple
dispatch, which is the main reason \elr{} doesn’t work on \emacsv{24.5}.

While \emacs{} has a pre-defined set of types which may form a valid stream
(with the function type being the most general), \elr{} provides a
\fun{defclass} and \fun{cl-defgeneric} based extension mechanism.  This is
discussed in detail in section \ref{sec:stream-types}.

% \begin{enumerate}
% \item Possibility of higher order programs, i.e. macros.
% \item Possibility of communicating via sexps, similar to XML.
% \item Possibility of very powerful editing tools.
% \item Possibility of a customizable syntax.
% \end{enumerate}

% The first category enables programs which transform and write programs.  This
% can even happen at runtime, if needed, and---depending on the particular Lisp
% implementation---may even be compiled at runtime to provide high speed.

% The second category simply means that data may be printed and read back in the
% languages own syntax, without having the need to devise an own syntax along with
% a parser.  This also frees the programmer from having to learn another language.

% The third category is---for the most part---beyond the scope of this thesis,
% although the customizability of the languages syntax does pose a problem for
% such tools.  The idea behind these tools is that they can view the source code
% in a similar fashion as the reader does: as a tree of expressions.  Such tools
% attempt to disallow and thus prevent the user from making any changes to the
% source which would result in an incorrect tree.  This does not mean that the
% source will always be free of errors: function calls may still have too many or
% too few arguments, functions or variables may be undefined.  Yet it is not
% possible to have too many opening or closing parens.

% These tools offer tremendous editing power, as they allow the programmer to
% perform operations on a tree.  Two examples of such tools I am aware of are
% paredit\cite{paredit} and lispy\cite{lispy}.  Both these tools are for Emacs and
% both are primarily directed at \el{}.  Yet because of the simplicity and
% (syntactic) similarity of Lisps, both tools can also be used for other Lisps
% like \cl{}, albeit with some restrictions and annoyances.\todo{add a reference
%   to the appropriate section, should I opt to add one.}

% The fourth category is the subject of this thesis.  Before discussing how an
% extensible reader works, it is necessary to first understand what a reader does,
% whether it is extensible or not.  This is discussed in section
% \ref{sec:reader-printer}.

\chapter{Reader and Printer}
\label{sec:reader-printer}

\section{Readers vs. Parsers}
\label{subsec:readers-vs-parsers}

Most texts discussing compilers, interpreters and other language processors
often use the terms \emph{lexer} and \emph{parser} to describe how text is at
first processed.  In the Lisp world, there is another term, often used instead:
the reader.

Lisps split the compiler or interpreter apart in a different way than most other
languages by allowing the user to read/parse an expression at runtime and to
provide hooks to the compiler in the form of macros.  Even Lisps which allow for
read macros like \cl{} lump the lexer and parser together and name it the reader
and make it a first-class service to the user.  This is because the Lisp reader
and its macros operate on single characters, and return anything from a single
token (a symbol) to a whole tree.  The details of this are discussed in section
\ref{subsec:read-algo}.

\section{Overview of the reader}
\label{subsec:reader}

The Lisp reader is responsible for transforming source code into Lisp objects.
In \el{} the rules for doing so are fixed.  The reader is implemented in C,
mostly by large switch statements, which look at the current character.
Normally parsers---and therefore readers---can perform their work by reading one
char, and being able to put one character back.  The built-in reader for \el{}
normally does this too, yet deviates from this procedure at least
once\footnote{This is done at least in the implementation of a rather obscure
  macro character: \#@.  This char is used to skip over bytes in the stream.
  The byte compiler places such characters into its output in order to skip over
  docstrings.  The strange behaviour is probably for historic reasons, as wrong
  input is purposefully accepted in certain situations as \emacs{} used to
  produce wrong output due to a bug.}.

\subsection{A sketch of rules for \emacs’ reader}
\label{subsubsec:rules-sketch}

The reader API only provides for the possibility to read \emph{one} expression
from a stream, at the current position: the function \Read{}.  This
expression can be very complex, because of composite structures like lists.
When the reader encounters a special char (a macro character) as its first char,
it follows the rules for such a char.  Should such a char be encountered while
reading a symbol or number (both are called ``atoms''), it stops in order to
return the atom read so far\footnote{An example of such behaviour is when
  reading the expression ``(foo bar)''.  When the reader attempts to read the
  second symbol it encounters a closing paren after the letter `r'.  At this
  point, the reader puts the read closing paren back onto the stream.}.  Only
when the reader is called again, it sees the macro char again.

When encountering a macro char as the first char, the according procedure is
called.  Obviously the opening parenthesis must be such a char: it triggers the
creation of a list.  It recursively calls \Read{} until it sees a closing
parenthesis.  This means that recursive calls to \Read{} may also see an open
paren as their respective first char, thus allowing nested calls to macro char
functions.

Note that \emacs{}’ reader does not actually have a strict notion of macro
characters and the like.  This is because \emacs{}’ reader does not have an
extensible reader; the reader itself knows all rules and how to handle macro
characters.

Most syntactic constructs simply start with a triggering char and have somewhat
straightforward rules regarding the construction of an object from characters.
The aforementioned list is one example, the vector, written as [a b c] is
another: here the tokens read are not evaluated\footnote{This means that reading
``[(list 1 2)]'' does not result in a vector with a single element which in turn
is a list containing the numbers 1 and 2, but a vector with the list consisting
of the symbol \sym{list} and the numbers 1 and 2 as its sole element.}.  Quoting
is also very simple: the single-quote character triggers a macro, which in turn
reads exactly one expression and returns a two element list: the symbol
\sym{quote} as the first element, and the read expression as the second element.

Other forms are more intricate and require non-trivial solutions, most notably
dotted pair syntax.  In Lisp, a cons cell (which is an ordered pair) may be
constructed with the function \fun{cons}, with list syntax or with dotted pair
notation.  The function \fun{cons} takes two arguments and returns a cell
consisting of these two objects.  List notation with parentheses constructs a
series of cells which point to their successor in the second field.  This means
that the second element must be another cons cell, or \nil{}, which designated the
empty list.  To construct a cons which does \emph{not} point to another cons or
\nil{} at read time, one may employ dotted pair syntax.  This constuct is like a
list, yet between the last and second to last elements a sole dot is inserted,
like so:

\begin{lstlisting}[style=lispinline]
  (foo bar spam . eggs)
  (spam . eggs)
\end{lstlisting}

The first example constructs a so called \emph{non-proper} list; such a list
does not end with a pointer to \nil{}.  It thus produces 3 cons cells.  Without
the dot, 4 cells would have been produced, in order to have a reference to
\nil{} at the end.  The second example produces a single cons cell, equivalent
to calling \texttt{(cons 'spam 'eggs)} at read time.

Note that this read construct is a deviation from a previously introduced one:
the list.  Also, symbols consisting only of a dot, as used here, are otherwise
not permitted, neither in \el{} nor \cl{}.  Both \emacs{} and the code used in
this thesis use a similar strategy to resolve this issue, as is discussed in
section \todo{Add a ref!}.

% The reader is a part of a Lisp system.  As outlined before, a string of
% characters (source code) is transformed into an AST in any language.  In Lisp,
% the syntactic layer is very thin, which makes the structure of the resulting AST
% apparent in the source code, as no special constructs are needed for loops,
% function definitions, types or the like.

\section{Overview of print syntax}
\label{subsec:print-syntax}

The printer is a part of a Lisp system, which works in tandem with the reader.
While a reader converts a textual representation into an object, the printer
converts an object into a textual representation.  It can be seen as the inverse
to the reader, yet while being a nice metaphor, it does not hold for all inputs.

As Lisp systems tend to be highly interactive, most lisps provide a means to
print values to a stream.  What Lisp does is slightly different to what many
other languages offer, as Lisp can often print back values in a way which are
valid input syntax.  How a data type is printed depends on the Lisp dialect.
Also not every dialect can print every data type.  Common Lisp by default cannot
print hash tables, and hardly any lisp has a meaningful printed representation
for functions---\el{} being an exception here.\footnote{\el{} can print
  interpreted functions as lists of symbols, and byte-compiled functions as
  bytevectors.  These may not be readable by a human, and barely compatible with
  other \emacs{} versions, yet is still more than most other dialects and
  implementations have to offer.}

Lists are among the types which have not only meaningful print syntax, but also
one which is compatible with its read syntax.  This means that a list, as shown
above, looks the same when printed, as it did in the source code---with minor
exceptions, which have to do with evaluation.  Also, formatting and comments are
lost.

As a fully fledged and extensible printer is a topic in its own right, further
details are beyond the scope of this thesis.  An extensible printer for \emacs{}
would not only bring \el{} a little closer to \cl{}, it would also make \elr{} a
little more valuable, especially in aiding communication between programs.

% \begin{lstlisting}[style=lispinline]
%   (+ a (* b c))
% \end{lstlisting}

% results in a Lisp object.  When this object is printed back, it looks (almost)
% exactly the same\footnote{A few things, such as comments and indentation are
%   lost, but otherwise it looks the same.}.  In Emacs, this can easily be tried
% out: In the *scratch* buffer, put the following expression: \textbf{(read "(+ a
%   (* b c))")}, place the cursor on the end of the expression and press C-c C-e.
% The very same text should appear on the status line.  The same can be done in
% almost any lisp environment in some form.  

% This allows users to print data to a file or network and read them back in
% again.  This is what Paul Graham meant when he claimed that programs
% communicating via sexps was an idea recently reinvented by XML.

\begin{comment}
  The reason why lisp code has so many parentheses, is that parentheses denote a
  list in Lisp.  Expressions in general, save the most trivial ones, are
  represented of lists containing other lists and symbols.\footnote{Plus of
    course other entities such as numbers, yet these are not relevant to this
    discussion.}
\end{comment}
% \chapter{Introduction}
% \label{sec:introduction}

% This thesis discusses the design, implementation, and idiosyncrasies of \elr{},
% an extensible reader for \el{}.  An overview over the history of Lisp, Emacs and
% \el{} are given, as well as an introduction to 

% \chapter{Introduction}
% \label{sec:introduction}
% In this thesis, a \cl{} like extensible reader for \el{} is discussed.  Before
% discussing the reader itself, it is important to discuss what a reader does,
% what it can do, and how the built-in reader in \emacs{} differs from the
% extensible one discussed in this thesis, or the \cl{} reader, from which this
% reader draws its inspiration.

% For this purpose, Lisps syntax, and how it is different from almost all other
% languages, is discussed.

% It is also shown what can be done with such an extensible reader, and why one
% might want to use such extensions.

% The application of such an extensible reader allows the creation of new
% syntactic constructs, which may be embedded into the language.  Thus, it enables
% the user to not only create a DSL, but also to embed it into a greater program,
% without making the new constructs opaque by putting them into strings, which
% must be parsed at runtime.


% In this thesis, the author wishes to first convey how Lisps syntax is different
% from other languages and why this is relevant to the discussion of extending the
% syntax.  Secondly what is meant by an extensible syntax or read macro, and why
% they might be relevant.  Also, depending on the background of the reader of this
% text, one might confuse such syntactic extensions with Domain Specific
% Languages—or DSLs for short.

% While there is some overlap between the two, DSLs are not necessarily embedded,
% but instead may come with a separate compiler and/or interpreter.  An extensible
% syntax, as it is presented here, allows to change the syntax on-the-fly,
% possibly without altering any present syntactic constructs, thus allowing new
% constructs in an existing programming language.

\section{Terminology}
\label{subsec:terminology}

Before describing the algorithm used to transform source code to lisp objects,
it is important to define some terms which will be used to describe the
process.  These terms are all defined in the Hyperspec, which is often regarded
as a free alternative to the \cl{} standard.

\subsection{General Terms}
\label{subsubsec:general-terms}

\begin{description}
\item[Terminating macro character] A character which has been marked as a
  terminating macro character must have a function attached to it, even if this
  function only signals an error when called.  Such characters also terminate
  any token which occurs before them.  If, for instance, `(' is such a
  character, the character sequence ``bar(...'' will stop reading between the
  `r' and `(', resulting in the symbol \sym{bar}.

  If such a character is encountered as the first char to \Read{}, its
  associated function is called.
\item[Non-terminating macro character] These characters work in a similar
  fashion to Terminating macro characters, yet do not terminate a token
  preceding them.  As with a terminating macro char, the associated function is
  called if it is the first character encountered.
\item [Read macro] A read macro is a pair of a (non-)terminating macro character
  and a function, which is associated with it.  The two together create the
  possibility to define new syntactic constructs.
\item[Syntax Type] At any given time every character has exactly one syntax
  type.  Note that different occurrences of the same character can have
  different syntax types.  It is thus not sufficient to provide a relation
  between the character value and a syntax type.  See paragraph
  \ref{subsubsec:syntax-type} for more details.
\item[Token] A token is an atomic unit of text which has been read by the
  reader.  As it is atomic, no unescaped terminating macro characters can be
  part of it, as they trigger a separate call to \Read{}.  When a token has been
  accumulated, the reader tries to interpret said token as a number (or in
  \cl{}’s case also as a so-called ``potential number'').  Should such an
  interpretation be successful, the given number is returned.  Otherwise the
  token is interpreted as a symbol.  As this step is rather isolated, this step
  is performed by the built-in reader in \elr{}.  This yields significant
  performance gains, as this step is typically performed very often.
\end{description}

\subsection{Character Syntax Types}
\label{subsubsec:syntax-type}

The six following Syntax Types for characters exist.  Note that while each
character always has exactly one type, this type may change over time, and does
this per character instance.  I.e not every `A' has the same syntax type.

\begin{description}
\item[constituent] Constituent characters are characters which may be part of a
  symbol or (potential) number.
\item[macro character] Macro characters come in two flavours: terminating and
  non-terminating (see also section \ref{subsec:read-algo}).
\item[single-escape] A single escape character escapes the following character
  in the stream.  This means that the syntax type of the next char is changed to
  constituent, no matter what its original type.  It also hat \emph{alphabetic}
  as its only trait (see section \ref{subsubsec:traits} for details).
\item[multiple escape] A multiple escape character escapes all following
  characters until another multiple escape char occurs.  Nested single escape
  characters are ignored, yet do not reverse escaping.
\item[whitespace] Characters of this type end the accumulation of a token
  (i.e. number or symbol).  They are thus used to separate expressions (for
  instance the elements of a list).
\item[invalid] Characters which may not be part of a token.  Note that this set
  may be empty and is in \elr{}.
\end{description}

\subsection{Character Traits}
\label{subsubsec:traits}

A character which has the syntax type constituent has one or more traits.
The following traits are available:

\begin{itemize}
\item alphabetic
\item digit
\item package marker (not used by \elr{})
\item plus sign
\item minus sign
\item dot
\item decimal point
\item ratio marker
\item exponent marker
\item invalid
\end{itemize}

These traits should be rather self explanatory, with the possible exception of
\emph{alphabetic}: characters with the trait alphabetic can be considered as
``not special''; i.e. can be part of a token, but not of a number.  By virtue of
having the syntax type constituent, no character having any traits can be a
macro character or escape further characters.  When considering that ``3e5'' is
a number, yet ``35e'' is a symbol, it becomes clear that the two occurrences of
the letter `e' can have different traits.  The same holds true for syntax types.

Note that most of these traits are used to construct (potential) numbers.

\section{Reader algorithm}
\label{subsec:read-algo}

As it is the goal of this thesis to provide an extensible reader in spirit and
style of \cl{} it is imporant to highlight the rules of \cl{}’s reader and how
\elr{} deviates from these rules.

The algorithm which \cl{} adheres to is detailed in the HyperSpec in section
2.2\cite{hyperspec}.

It is worth noting that in \cl{} the reader revolves around a central opaque
data structure: the readtable.  Every customization which is made, is made to a
readtable.  Some functions take a readtable as an optional argument while
defaulting to the current readtable (stored in the special variable
\sym{*readtable*}), or simply always using the default table.  Note that this
table can be dynamically rebound, as it is a so called special variable,
i.e. its binding follows a stack discipline.

The reader consists of 10 numbered steps:

\begin{enumerate}
\item Read a character from the input stream into \texttt{X}.  If at
  end-of-file, act according to \texttt{eof-error-p} and \texttt{eof-value}.
  If \texttt{eof-error-p} is non-\texttt{nil} (the default) signal an error.
  Otherwise return \texttt{eof-value} (\texttt{nil} by default).

  According to the syntax type of \texttt{X}, control is dispatched to one of
  the steps 2 to 7, some of which transfer control to steps 8 to 10.
\item If \texttt{X} is an invalid character, signal an error of type
  \texttt{'reader-error}.  In the current implementation of \elr{} this will not
  happen, as no character is marked as explicitly invalid.
\item If \texttt{X} is a whitespace character, discard it and jump to step 1.
  Normally this would be done with a tail call, yet had to be implemented with a
  sort of trampoline.  This branch returns a marker object, which determines
  whether to start again or return the value returned by the conditional
  expression as a whole.
\item If \texttt{X} is a macro character, either terminating or non-terminating,
  its associated function is executed.  The current input stream and the
  character (\texttt{X}) itself are passed as arguments.  Note that this step
  only occurs when looking at the first character since the invocation of the
  current \Read{} frame!  The open parenthesis in ``foo(bar'' would \emph{not}
  trigger this behaviour, ``(foo'' on the other hand will.

  Before calling the associated function, a special variable which allows for
  dotted pair notation is bound to \texttt{nil} for the duration of said inner
  call.  The return value of the associated function is the return value of the
  conditional being discussed at the moment, unless it is not a list of
  arbitrary length.  Further dispatching on the length of the list (especially
  if the list is empty) is done outside of this conditional and is discussed
  later.  This will become critical to comments.

  It is critical that the reader macros perform no side-effects other than
  advancing the stream, as code may be read zero or more times.  This is
  especially true when \Read{} is called by editing tools, as they may read
  inner or outer parts of an expression which overlap, and do not care for any
  effects designed for the program which is being edited.
\item If \texttt{X} is a single escape character, another character from
  the stream is read into \texttt{Y}.

  The syntax type of \texttt{Y} is set to constituent with alphabetic being its
  only trait.  An additional property is added to \texttt{Y}, namely
  \texttt{escapedp}.  The resulting character starts a new token, which is
  further processed in step 8.  Note that syntax type, traits and other
  properties are unique to every character.  An unescaped 'A' is a different
  object from an escaped 'A'.  More details on data structures used are given in
  section \ref{subsec:datastructures}.

  Escaping characters can be used to allow characters in a symbol for which
  there is normally no read syntax.  For instance, in and of itself, a symbol
  may be named ``(foo)'' (note the parens, which would normally make up a list).
  One way of obtaining such a symbol is by calling \texttt{intern}---which takes
  a string---at runtime:

  \begin{lstlisting}[style=lispinline]
    (intern "(foo)")
  \end{lstlisting}

  The alternative is using escaping to allow this name at read time:
  
  \begin{lstlisting}[style=lispinline]
    \(foo\)
  \end{lstlisting}
\item If \texttt{X} is a multiple escape character, a new empty token is begun
  and control is transferred to step 9.  Note that the escape character itself
  is consumed from the stream.
\item If \texttt{X} is a constituent character, it begins a new token and enters
  step 8.

  The new token initially consists of one character, \texttt{X}, which has
  copies of its syntax type and traits attached to it.
\item At this point an even number of multiple escape chars have occurred
  (i.e. none are currently in effect), and a token is accumulated.

  A new character \texttt{Y} is read from the input stream.  If end-of-file is
  reached, the token so far is processed.  The resulting token is the return
  value for this branch.

  Another dispatch on the syntax type of \texttt{Y} is performed:
  \begin{enumerate}
  \item If \texttt{Y} is invalid, an error of type \texttt{'reader-error} is
    signaled.  In the current implementation of \elr{} this will not happen, as
    no character is marked as explicitly invalid.
  \item If \texttt{Y} is a single escape char, a new char \texttt{Z} is fetched
    from the input stream and appended to the current token as an alphabetic
    constituent with the \texttt{'escapedp} property.
  \item If \texttt{Y} is a multiple escape char, the character is consumed as
    usual, the token is left as is (possibly left empty).  Finally, step 9 is
    entered.
  \item If \texttt{Y} is a terminating macro character, \texttt{Y} is put back
    into the stream and the token so far is processed.  The processed token (a
    symbol or a number) is returned, thus \Read{} is done.
  \item If \texttt{Y} is a whitespace character, \texttt{Y} is put back into the
    stream if \texttt{*el-reader/preserve-whitespace*} is true.  In both cases
    the token is processed and returned, thus \Read{} is done.
  \item If \texttt{Y} is a constituent or \emph{non}-terminating macro
    character, it is appended onto the token and step 8 repeats.
  \end{enumerate}

  In summary: a single escape char is dealt with in place, a multiple escape
  char hands the token over to code expecting to escape everything (step 9),
  macro characters and whitespace terminate reading\footnote{} and constituent
  and non-terminating macro characters are appended to the token.

\item At this point an odd number of multiple escape characters have been
  encountered (i.e. escaping is in effect). 
  \begin{enumerate}
  \item If \texttt{Y} is either constituent, macro character (terminating and
    non-terminating alike) or whitespace, \texttt{Y} is appended onto the stream
    as an alphabetic constituent with the property \texttt{'escapedp} before
    repeating step 9.
  \item If \texttt{Y} is a single escape character, it is appended to the token
    as an alphabetic constituent with the \texttt{'escapedp} property and step 9
    is repeated.
  \item If \texttt{Y} is a multiple escape character, it consumed without adding
    it to the token before switching back to step 8.
  \end{enumerate}
\item An entire token has been accumulated.  The token is first checked for
  whether or not it constitutes a valid number.  If so, that number is the
  result of this step and hence of \Read{}.  Otherwise a symbol is constructed.
  While \elr{} contains code to do this in \el{}, it is only used if escaped
  characters were encountered.  Otherwise \elr{} removes its own advice from
  \Read{}, calls \Read{} with the token and reinstates the advice.  This is done
  for performance reasons, as the steps taken are exactly the same in \elr{} and
  the built-in reader.  It seems as if is were faster to replace the escaped
  characters in the token with backslashes again and let the built-in reader do
  the job in all cases, yet such a string transformation is so costly that it is
  almost exactly as fast.  Such code exists in \elr{}, yet is not used.
\end{enumerate}

Figure \ref{code:read-algo} shows the corresponding \el{} code.  Note that many
steps have very straightforward translations, while the lack of multiple-values
and tail-call optimization make rather ugly looping a necessity.  Also, steps 8
and 9 have been pulled out as extra functions and put in front of
\fun{el-reader/read}. 

\begin{lstlisting}[style=lispcode,label={code:read-algo},caption={Code for the
    reader algorithm.},numbers=left]
(cl-defun el-reader//step-8 (input-stream token _x)
  ;; Loop until we do an explicit return.  This would have been so much
  ;; nicer with tco.  *sigh*
  (let (y)
    (while t
      (setf y (condition-case nil
                  (el-reader/getch input-stream)
                (end-of-file (cl-return-from el-reader//step-8
                               (el-reader//process-token token)))))
      (cond ((el-reader//rt/invalid-syntax-type-p
              *el-reader/readtable* y)
             (signal 'reader-error (list "Invalid character" y)))
            ((el-reader//rt/single-escape-char-p
              *el-reader/readtable* y)
             (setf token (s-concat token
                                   (el-reader//put-escaped-prop
                                    (el-reader//force-alphabetic
                                     (el-reader/getch input-stream))))))
            ((el-reader//rt/multiple-escape-char-p
              *el-reader/readtable* y)
             (cl-return-from el-reader//step-8
               (el-reader//step-9 input-stream
                                  token
                                  y)))
            ((el-reader//rt/terminating-macro-char-p
              *el-reader/readtable* y)
             (el-reader/getch input-stream y)
             (cl-return-from el-reader//step-8
               (el-reader//process-token token)))
            ((el-reader//rt/whitespacep *el-reader/readtable* y)
             (when *el-reader/preserve-whitespace*
               (el-reader/getch input-stream y))
             (cl-return-from el-reader//step-8
               (el-reader//process-token token)))
            ((or (el-reader//rt/constituentp *el-reader/readtable* y)
                 (el-reader//rt/non-terminating-macro-char-p
                  *el-reader/readtable* y))
             (setf token (s-concat token
                                   (el-reader//defaults-to-str-props
                                    y))))))))

(cl-defun el-reader//step-9 (input-stream token x)
  ;; At this point a token is being accumulated, and an odd
  ;; number of multiple escape characters have been encountered.
  (let (y)
    (while t
      (setf y (el-reader/getch input-stream))
      (cond
       ((funcall (apply
                  #'-orfn
                  (seq-map
                   (lambda (fn)
                     (-partial fn *el-reader/readtable*))
                   (list
                    #'el-reader//rt/constituentp
                    #'el-reader//rt/terminating-macro-char-p
                    #'el-reader//rt/non-terminating-macro-char-p
                    #'el-reader//rt/whitespacep)))
                 y)
        (setf token (s-concat token (el-reader//put-escaped-prop
                                     (el-reader//force-alphabetic y)))))
       ((el-reader//rt/single-escape-char-p *el-reader/readtable* y)
        (setf token (s-concat
                     token
                     (el-reader//put-escaped-prop
                      (el-reader//force-alphabetic
                       (el-reader/getch input-stream))))))
       ((el-reader//rt/multiple-escape-char-p *el-reader/readtable* y)
        (cl-return-from el-reader//step-9
          (el-reader//step-8 input-stream token x)))
       ((el-reader//rt/invalidp *el-reader/readtable* y)
        (signal 'reader-error "Invalid char"))))))

(cl-defun el-reader/read (&optional input-stream (eof-error-p t)
                                    eof-value recursive-p keys)
  (let ((res *el-reader/repeat-read*)
        (input-stream (el-reader//get-getch-state input-stream)))
    (while (eq res *el-reader/repeat-read*)
      (setf
       res
       (let ((x (condition-case c
                    (el-reader/getch input-stream)
                  (end-of-file
                   (if eof-error-p
                       (signal (car c) (cdr c))
                     (cl-return-from el-reader/read eof-value))))))
         (when (not recursive-p)
           (setf *el-reader//read-objects* nil
                 *el-reader//circular-read-functions* nil))
         (cond ((el-reader//rt/invalid-syntax-type-p
                                    *el-reader/readtable* x)
                (signal 'reader-error (list "Invalid char" x)))
               ((el-reader//rt/whitespacep *el-reader/readtable* x)
                *el-reader/repeat-read*)
               ((el-reader//rt/terminating-macro-char-p
                 *el-reader/readtable* x)
                (let ((*el-reader//allow-single-dot-symbol* nil))
                  (let ((res (funcall
                              (gethash x (el-reader//rt/term-mac-fns
                                *el-reader/readtable*))
                              input-stream x)))
                    (when (not (listp res))
                      (error (s-join
                              " "
                              '("Read-macro functions must always"
                                "return a (possibly empty) list."))))
                    res)))
               ((el-reader//rt/non-terminating-macro-char-p
                 *el-reader/readtable* x)
                (let ((*el-reader//allow-single-dot-symbol* nil))
                  (let ((res (funcall
                              (gethash
                               x
                               (el-reader//rt/non-term-mac-fns
                                *el-reader/readtable*))
                              input-stream x)))
                    (when (not (listp res))
                      (error (s-join
                              " "
                              '("Read-macro functions must always"
                                "return a (possibly empty) list."))))
                    res)))
               ((el-reader//rt/single-escape-char-p
                                    *el-reader/readtable* x)
                (cl-values (el-reader//step-8
                            input-stream
                            (el-reader//put-escaped-prop
                             (el-reader//force-alphabetic
                              (el-reader/getch input-stream)))
                            x)))
               ((el-reader//rt/multiple-escape-char-p
                                    *el-reader/readtable* x)
                (cl-values (el-reader//step-9 input-stream "" x)))
               ((el-reader//rt/constituentp *el-reader/readtable* x)
                (cl-values (el-reader//step-8
                            input-stream
                            (el-reader//defaults-to-str-props x)
                            x)))))))
    (if (plist-get keys :return-list)
        res
      (if res
          (car res)
        (let ((res))
          (while (not res)
            (setf res
                  (el-reader/read input-stream eof-error-p eof-value
                                  recursive-p '(:return-list t))))
          (car res))))))
\end{lstlisting}


\section{Additional algorithms}
\label{sec:add-algos}

While section \ref{sec:read-algo} details the reader algorithm itself, it alone
is not sufficient to read lisp code.  For instance, the reader algorithm does
not specify a single macro character.  While simple ones like \fun{quote} are
very simple, matching pairs of characters is a little more tricky.  When an open
parenthesis is encountered, it starts reading elements with recursive calls to
\Read{}.  Yet the reader algorithm itself does not specify how to reliably
detect when to stop reading, unless end-of-file is encountered.  One cannot
simply check whether the next character in the stream is a close paren, as
comments and whitespace may lie in between the current position and the closing
paren:

\begin{lstlisting}[style=lispinline]
  (foo ;; comment
    bar)
\end{lstlisting}

This is why the function \fun{read-delimited-list} exists.

\subsection{read-delimited-list}
\label{subsec:read-delimited-list}

The purpose of \fun{read-delimited-list} is to read successive elements from the
input stream until a terminating character is found, returning the read elements
as a list.  For almost all purposes the terminating character must be a
terminating macro character, as it may otherwise be consumed by inner tokens.
For instance, in ``(foo bar)'' the second element would read as ``bar)'' if
``)'' was not a terminating macro character.  The terminating character is
consumed when encountered, thus the associated code is only executed on
incorrect input.  For this reason, most characters used as closing delimiters
reuse the definition for the closing parenthesis, which unconditionally signals
an error.

The function \fun{read-delimited-list} must know details about the inner
workings of the reader implementation, as it must check a characters syntax
type, which is not normally part of the public API.

Its signature is as follows:

\begin{lstlisting}[style=lispinline]
  (el-reader/read-delimited-list char &optional stream
    recursive-p)
\end{lstlisting}

As before, the discussion of how the function works will be followed by the code
itself.

\fun{read-delimited-list} looks one char ahead, i.e. reads a character without
consuming it.  None of the code discussed so far does this directly.  While not
relevant to any stream type built into \elr{}, it may be possible for a stream
to support unreading of only one character, thus \fun{el-reader/peek-char} is
used.

The following steps constitute the algorithm for \fun{read-delimited-list}:

\begin{enumerate}
\item The character \sym{C} is obtained by \fun{el-reader/peek-char}.
\item \label{loop-step}
  If \sym{C} matches \sym{char} (i.e. the character to terminate the list)
  the character is consumed from the list.  Finally, the reversed list of read
  objects is returned.
\item Depending on the syntax type of \sym{C}, one of the following actions is
  performed:
  \begin{enumerate}
  \item If \sym{C} is invalid, a \sym{'reader-error} is signaled.
  \item If \sym{C} is whitespace, \sym{C} is consumed from the input stream and
    a new character is read with \fun{el-reader/peek-char} and stored in
    \sym{C}.
  \item If \sym{C} is a constituent, macro character (terminating or
    non-terminating), or an escape character (single or multiple), \Read{} is
    called to potentially produce an object.  If \Read{} returns no object (in
    the default configuration this only happens on comments), the whole process
    is repeated, now with an advanced input stream.  Otherwise, the returned
    object is added to the front of a list of objects (initially empty).
  \end{enumerate}
\item Control is transferred back to step \ref{loop-step}.
\end{enumerate}


\begin{lstlisting}[style=lispcode,label={code:read-delim-list},caption={Code for
  \fun{read-delimited-list}},numbers=left]
(defun el-reader/read-delimited-list (char &optional stream
                                           _recursive-p)
  (let ((end-res *el-reader/repeat-read*))
    (while (eq end-res *el-reader/repeat-read*)
      (setf
       end-res
       (let ((res-list nil)
             (c (el-reader/peek-char stream)))
         (while (/= c char)
           (cond
            ((el-reader//rt/invalid-syntax-type-p
              *el-reader/readtable* c)
             (signal 'reader-error (list "Invalid char" c)))
            ((el-reader//rt/whitespacep *el-reader/readtable* c)
             (el-reader/getch stream)
             (setf c (el-reader/peek-char stream)))
            ((or (el-reader//rt/constituentp *el-reader/readtable* c)
                 (el-reader//rt/terminating-macro-char-p
                  *el-reader/readtable* c)
                 (el-reader//rt/non-terminating-macro-char-p
                  *el-reader/readtable* c)
                 (el-reader//rt/single-escape-char-p
                  *el-reader/readtable* c)
                 (el-reader//rt/multiple-escape-char-p
                  *el-reader/readtable* c))
             (let ((res (el-reader/read stream t nil t
                                        '(:return-list t))))
               (if res
                   (if (listp res)
                       (push (car res) res-list)
                     (error (s-join
                             " "
                             '("Read-macro functions must always "
                               "return a (possibly empty) list."))))
                 *el-reader/repeat-read*))
             (setf c (el-reader/peek-char stream)))))
         (el-reader/getch stream)
         (reverse res-list))))
    end-res))
\end{lstlisting}


% TODO NEXT: put in source code and walk through it?  Do so for the reader
% algorithm too?  Explain what the function does, possibly even the messy bits
% about missing tail calls and multiple-values.

\begin{comment}
  \chapter{Lisp Basics}
  \label{subsec:lisp-basics}

  This section is only intended as a short recap of what Lisp syntax is, and how
  it relates to the reader.  For more details, a Lisp textbook is more
  appropriate.  A good reference for \el{} is found at \cite{elisp-reference}.

  Lisp syntax never directly describes control flow, function definitions, or
  other actions, but merely data.  If the described data consists of lists and
  symbols, it will later on be treated as code, which can be compiled and
  executed.\todo{Possibly show some Lisp examples.}

  Such data structures can represent code by having a list with an ``action'',
  which may be a special form, a macro or a function, as its first element.  Any
  further elements are arguments to said operator.

  As an example, here is some code which performs a variable binding with
  \fun{let} (which is a special form), an assignment with \fun{setf} (a macro)
  and a function call to \fun{message}.

\begin{lstlisting}[style=lispinline]
  (let ((var 5)) (setf var "Hello") (message "\%s" var))
\end{lstlisting}

When Lisp source code is processed, it goes through three distinct stages:
reading, macro expansion (optionally this can also be a compile phase), and
evaluation (which can be the execution of compiled code).

The first stage is somewhat unique to Lisp---most languages only have this as an
implementation detail in the compiler or interpreter.

\section{Reader}
\label{subsec:reader}

The reader is the first stage which code runs through.  This part of the
evaluation mechanism is the only part which sees individual characters.  As Lisp
syntax consists of literal representation of data, not of control structures and
the like, the reader transforms these literal representations into data
structures, which may be treated as executable code later on.

The reader is the part of the evaluator which knows that parentheses denote
lists, square brackets denote vectors, how to read numbers, symbols and so on.

It also defines where a token ends, in the absence of whitespace. For instance,
the following expressions are all slightly different textual representations of
the same object, i.e. later stages cannot distinguish between the two.

\section{Macro expansion}
\label{subsec:macro-exp}

\section{Evaluator}
\label{subsec:evaluator}



\chapter{Reader basics}
\label{sec:reader-basics}

Before discussing what the reader is and what it does, it is important to first
introduce a few important data types.
\section{Important Lisp Data Types}
\label{subsec:important-types}

A few Lisp data types are of particular importance, both because they are
relatively rare in other languages, but also because they are very widespread in
Lisp code, i.e. the reader often creates them.

Every Lisp dialect the author is aware of provides at least the following:

\subsection{Symbols}
\label{subsubsec:symbols}

The symbol is a type, which represents a name, often together with places for
values and/or functions.  The latter depend on the Lisp dialect.  An important
property of symbols is that fast lookup is supported, and that symbols are
interned.  This means that each symbol which is read, which has the same name,
returns the same Lisp object.\footnote{This is, in effect, a singleton.}

In \el{}, which is the Lisp under consideration for this thesis, a symbol has
the following attributes:

\begin{description}
\item[{Name}] A (typically hashed) name for the symbol.  This may be retrieved
  as a string at any time.
\item[{Value}] This is the value of the symbol.  It may be retrieved by a call
  to \fun{symbol-value} or by simply appearing in a program (macros or special
  forms may treat symbols differently).
\item[{Function}] This cell is looked up if the symbol is the first element of a
  list which is evaluated (more on this later).  Alternatively, a call to
  \fun{symbol-function} returns the function to which it points (if any).
\item[{Property List}] A symbol may also have a Property List, or plist for
  short, which is a mapping from a key (mostly a symbol) to a value.  This is
  intended as a mechanism to store arbitrary metadata in a symbol.
\end{description}

\subsection{List}
\label{subsubsec:list}

In Lisp parlance, when a list is mentioned, it is almost always a singly linked
list.  While by far not the only compound data structure\footnote{Strictly
  speaking, lists by themselves to not exist: there are only cons-cells, yet
  this nuance is not very important for the current discussion.}, it is a very
important one.

Not only is there syntax for lists---in the form of parentheses---together with
the symbol, the list is used as the prime representation for code.  The
following section hat some examples, as it discusses the result of calling the
reader.
\section{Lisp basics}
\label{subsec:lisp-basics}

This section is about a few basics of Lisp, not so much the reader.  Here it is
discussed how nested lists can represent such actions as function calls,
assignment and function definitions, as Lisp does not have any syntax for those.
\paragraph{Function call}
\label{par:function-call}

In Lisp a function call happens when the evaluator comes across a list form.  In
such a case the first element is taken to be a function and the other elements
are its arguments.  Here is the canonical hello world program for \el{}:

\begin{lstlisting}[style=lispinline]
  (print "Hello, world")
\end{lstlisting}

Here we have a list of two elements.  The first element happens to be a symbol,
which has a function associated with it.  The second element (a string in this
case) is evaluated (nothing special happens here, as strings evaluate to
themselves, contrary to lists) and passed as the sole argument to the function
named by the symbol print.

\paragraph{Assignment}
\label{par:assignment}

An assignment is either a special form, i.e. a primitive which the
implementation must provide, or a macro (which expands to other code, eventually
leading to a special form).  Here the low level special form was chosen.  To
assign the value 5 to the ``variable'' \sym{x} with a such a low level special
form, we could write the following:

\begin{lstlisting}[style=lispinline]
  (set (quote x) 5)
\end{lstlisting}

The \fun{quote} form around \sym{x} tells the evaluator to \emph{not} evaluate
\sym{x}, but to pass it on as the symbol itself.  Note that the reader would
have created the symbol \sym{x}, and only the evaluator can care about any
meaning for \sym{x}.  Many language implementations throw symbols away at
runtime.  This is also possible in Lisp, as the compiler can remove symbols and
their lookups in many situations.

Note that although \fun{set} is a special form, it too is invoked when it is the
first element in a list.  Like macros, but unlike functions, special forms may
control how to evaluate their arguments.

\paragraph{Function definition}
\label{par:function-def}
Unsurprisingly, a function is defined by a list form, with a special symbol as
its first element.  In \el{} this symbol is \fun{defun}.

\begin{lstlisting}[style=lispinline]
  (defun say-hello (text) (print text))
\end{lstlisting}

Note that the third element, although it is a list, is neither evaluated, nor
must it be quoted.  This is because \fun{defun} is a macro, and macros may
control how to evaluate their arguments.

\section{What does the reader do?}
\label{subsec:what-does-the-reader-do}
In a sense, every programming language has a reader.  Every language
implementation must provide some means of converting characters in source code
into data structures which are more meaningful to the later stages of
interpretation or compilation.

The difference in Lisp is that the reader is available to the programmer both at
runtime and compile time (if there is a compile phase).

This means, that an application may store data structures by printing them (for
instance to a file) and later reading them back.  If one had a list, containing
the symbol \sym{foo}, the number 3, the symbol \sym{bar} and the string "4",
printing might result in this: \footnote{The exact form depends on the dialect.
  If not otherwise stated, is assumed.  is also used extensively.}

\begin{lstlisting}[style=lispinline]
  (foo 3 bar "4")
\end{lstlisting}

This may later be read back with a call to \fun{read}, to retrieve a data
structure, which has the same shape as the original.  Note that this is not
syntax for code in the sense of execution, yet merely for data.  This is an idea
which pervades Lisp, as code is data, and data may be code.

If the code which was read in this example were to be evaluated (by calling
\fun{eval} on the result of the call to \fun{read}), \sym{foo} would be expected
to name a function, and \sym{bar} would be evaluated as a variable.  The
function named by \sym{foo}, if any, would then be called with the argument 3,
whatever \sym{bar} evaluated to, and the string "4".

The strict distinction between \emph{reading}, and \emph{evaluating} code is
what makes read macros possible.  It is also the reason for the parenthesis in
typical lisp code.  This is because the list (denoted by parenthesis) is the
structure in which code is held.  This is true for assignments, function calls,
function definitions etc.  Examples are given below.

\section{Properties of Lisp Syntax}
\label{subsec:properties-of-lisp-syntax}

The idea behind the syntax of Lisp is very different than in most other
programming languages.  While most languages provide constructs for assignment,
looping, function definition, etc, Lisp merely provides syntax for data
structures.  This idea has been reused in data description languages such as XML
and JSON, among others.  An expression in source form, which describes a Lisp
object is also called a symbolic expression, or sexp for short.  The term form
is also used on occasion.

So far, no evaluation rules have been discussed, and rightly so.  The evaluation
of code is not something the reader takes part in.  This is left to the
interpreter or the compiler.

\section{Intermezzo: syntax at runtime}
\label{subsec:intermezzo:syntax-at-runtime}

While some programming environments allow the user to load code at runtime, Lisp
also allows to read and compile code at runtime.  The former is exposed by a
function called \fun{read}.  This function is given at least one argument:
something which may be used to retrieve a character, and to put back at least
one character which has been read.  This function attempts to read one Lisp
object from the character stream, and returns said object if successful.

This aspect may be compared to an XML parser, which also merely describes data.
One difference is that a Lisp reader can be more flexible, as this thesis shows.
A further difference is that standard Lisp syntax\footnote{Standard syntax
  refers to the set of rules present when no modification has taken place since
  a fresh start of the environment.} is shorter when a lot of markup is needed.
I.e. writing programs in XML tends to be rather verbose, as such languages as
ant show \cite{ant}.  Writing a document in symbolic expressions would probably
be rather cumbersome, as either lots of strings must be used, or elaborate rules
for the treatment of special chars as apostrophes must be devised.

\section{Reader, Compiler, Interpreter}
\label{subsec:reader-compiler-interpreter}

In this section, an overview over the reader, compiler and interpreter, together
with their interactions is given, as it is relevant to the central point of the
thesis.

\chapter{Why Emacs?}
\label{sec:why-emacs}

The author chose to extend Emacs with an extensible reader, and not some other
member of the Lisp family, such as Clojure for several reasons.  One reason is
that the author has gained the most familiarity with \el{} and \cl{}.  The two
are reasonably similar in a number of ways, especially with \el{} growing a lot
in recent years.  \el{} used to have only dynamic scope, yet gained optional
lexical scope in version 24.1\cite{Emacs-Lexical},% \footnote{See
% \url{https://www.gnu.org/software/emacs/news/NEWS.24.1}}
giving \el{} both lexical and dynamic scope, as with \cl{}.  Also, in the next
version of Emacs, which will probably become version
25.1\cite{emacs-pretest},% \footnote{See
% \url{http://permalink.gmane.org/gmane.emacs.announce/59} for a source tarball.
% It contains a file etc/NEWS which details changes}
CLOS-style multiple dispatch generic functions have been added, which ease
development for many scenarios and again are a step towards \cl{}.

\el{} is also quite similar to \cl{} in many other rather minor respects.  Both
are a Lisp-2\footnote{Being a Lisp-2 means having separate namespaces for
  functions and variables.}, both use \sym{defun} to define functions and
\sym{defmacro} to define macros, both with a very similar and largely compatible
grammar.  \el{} also sports a built-in package called CL which tries to emulate
many \cl{} features, such as more features for default arguments, destructuring,
and the \cl{} \fun{loop} macro.

Emacs still has a long way to go before being as powerful as \cl{}, and probably
never will be, as multithreading, conditions and restarts, full CLOS support,
packages and some minor issues like returning multiple values and global symbol
macros are still missing.

As Emacs also does not feature a built-in extensible reader, this thesis
provided one to hopefully drive Emacs development forward some more.

\chapter{Reader internals}
\label{sec:reader-internals}

While the reader has a very simple interface, internally it must keep some
state, in order to know how to treat the characters encountered.  Some ephemeral
state is kept on the call stack and in closures, but the more important state is
kept in a structure called a readtable.

The readtable enables users to modify this state.  While it is possible for a
user to modify this structure directly, it is strongly discouraged.  Emacs has
no possibility to prevent users from seeing or modifying state, but through
compiled closures.

As a convention, symbols which are part of the public API are prefixed with
``el-reader/'', while symbols which are not part of the public API are prefixed
with ``el-reader//''.  Some symbols also use a sort of sub-namespace, i.e. are
prefixed with ``el-reader//rt/''.  This helps users to distinguish between
public API and internals on the basis of a symbol name.

The public API consists mostly of functions like
\fun{el-reader/set-macro-character}, which manipulate a readtable.

Many of these functions take a readtable as an optional argument.  If no
argument is given, the current readtable is used.  The current readtable is a
special variable named \sym{*el-reader/readtable*}.  The default value of this
variable is a readtable which mimics \el{}s default syntax as closely as
possible.  While this has not been achieved at the moment, it is possible to
complete the table with more read macros.  The heavy lifting, such as reading
circular data structures is already present.  Also, the most common constructs
used in \el{} are present.

The readtable provides the basis on which \elr{} decides how to treat
characters.  Characters have exactly one syntax type.

Note that not all characters which denote the same value have the same syntax
type and traits.  It is possible for a character (for instance when escaped) to
be treated as a constituent with the alphabetic trait, although it would
otherwise denote a macro character.  For instance: `(' is a macro character, but
if read as ``$\backslash$('', the open parenthesis will instead be treated as an
alphabetic constituent.  Traits such as alphabetic will be discussed in section
\ref{subsubsec:traits}.

\section{Syntax types}
\label{subsec:syntax-types}

Here all syntax types are listed.  These are very similar to the syntax types in
\cl{}, yet differ in a few points, as the main goal was not to parse \cl{} code,
but to be compatible to \el{}.

\subsection{Constituent}
\label{par:constituent}

Most characters are treated as ``constituent'' characters.  To be precise: if a
character does not have a different syntax type, it is constituent.  Constituent
characters may be part of a token.

Constituent characters also have traits, which will be discussed in the next
section.
\subsection{Invalid}
\label{subsubsection:invalid}

If the reader encounters an invalid character, an error is raised.  This does
not imply that no such char may be in the input stream.  A read macro may choose
to skip such characters, or may use them in creative ways.  This is completely
up to the user.  The default readtable does not specify any characters to have
the invalid syntax type.

\subsection{Whitespace}
\label{par:whitespace}

These are characters which serve no special meaning.  The name should be pretty
explanatory.

\subsection{Single escape}
\label{par:single-escape}

In standard \el{} a single escape char allows spaces and other characters which
do not comprise a symbol by itself to be part of one.  The sequence "foo bar"
would normally denote two tokens (from which two symbols will be created).
Should the desired name of \emph{one} symbol be "foo bar", a backslash is needed
(which is the sole default single escape char): "foo$\backslash$ bar" would read
as one token, not two.  This works in vanilla \el{}, although the author has
never seen this in the wild.

In \cl{} this is more important, as the reader up-cases all chars by default,
which escaping also inhibits.  This aspect of \cl{} was not incorporated into
\elr{}, as it is probably only present in \cl{} for historic reasons.

\subsection{Multiple escape}
\label{par:multiple-escape}

These chars are similar to single escape chars.  While a single escape only
escapes the next char, a multiple escape char escapes all chars up to the next
multiple escape char.  In \cl{} the `|' character is used by default, in \elr{}
the functionality is present, yet no character has been assigned, as most users
would not expect the pipe character to behave in such a way.

\subsection{Terminating macro character}
\label{par:terminating-macro-char}

These characters are what make read macros so interesting.  Every macro
character has an associated function, which is called with the character and the
current stream as arguments.

A function associated with a macro char may have no side effects apart from
advancing the stream, as such a function may make no assumptions about the
number of times an object is read.  Such a function may read one char at a time,
put back one read char which it has just read, and call \fun{read} on the
(possibly advanced) stream.

The function which is associated with a macro character shall return the read
object.

Terminating macro characters also terminate any token which may have been read
before encountering the macro character.  For example, `(' is a Terminating
macro character, which reads a list.  When the reader encounters the string
"foo(\ldots{}" it reads the constituents `f' `o' and `o'.  When `('---which is a
\emph{terminating} macro character---is encountered, it is put back into the
stream, and "foo" is treated as a token.  In the next call to \fun{read} (should
there be any), the function associated with `(' will be called, which in turn is
the result of the read call.

\subsection{Non-terminating macro character}
\label{subsubsec:non-terminating-macro-char}

These characters are very similar to \emph{terminating} macro characters.  The
only difference is how such a character is treated when constituents have been
read.  While reading a token, a terminating macro character is put back into the
stream and the already read characters form a token.  When a
\emph{non}-terminating macro character is encountered, the character is treated
as if it was a constituent and its function is \emph{not} called.  If no
constituents have been read before, an non-terminating macro character is
treated the same as a terminating macro character.


\subsection{Traits}
\label{subsubsec:traits}

Every character which is a constituent also has one or more traits, which
provide further information on its use.

\paragraph{Alphabetic}
\label{par:alphabetic}

characters are characters which may appear in a token.  Escaping may force this
trait on an otherwise non-constituent character.

\paragraph{Digit}
\label{par:digit}

characters may be treated as a number, if they form a token, and they are
compatible with the input base.

\paragraph{Package marker}
\label{par:package-marker}

characters were only implemented because \cl{} has them.  The only character
with this trait is the colon.  As Emacs uses so called obarrays to intern its
symbols, and it is not possible to intern a symbol into more than one array
% \cite{no-multi-intern}
, it is not possible to clone \cl{}s packaging mechanism to Emacs.  Hence this
syntax type is not of particular importance.

\paragraph{Plus sign, minus sign, dot, decimal point, ratio marker and exponent
  marker}
\label{par:number-traits}

are used while constructing numbers.

\paragraph{Invalid}
\label{par:invalid}

Should a character with this trait be encountered, an error is thrown.  So far,
\elr{} does not specify any characters to have this trait.
\end{comment}

\chapter{API overview}
\label{sec:api-overview}

The API of \elr{} takes lots of inspiration from the corresponding API in
\cl{}, as the two languages are sufficiently similar, and \cl{} has a very
mature library.  Also, it may be expected that some \el{} developers are
familiar with \cl{} read macros.  Those who are not may benefit from the
similarity, as learning and reference material on \cl{} read macros seems to be
more widely available than for any other Lisp, probably due to its stable
standard.  \footnote{Paul Grahams book ``On Lisp''\cite[p.~224]{on-lisp}
  contains a chapter explaining both regular macros and read macros.}

\section{The readtable}
\label{subsec:readtable}

The only user visible data structure is the readtable.  In \cl{} this type has
non-enumerable types, while in \elr{} it is defined in terms of
\fun{defclass}, hence is enumerable and even has public attributes.  Most users
will need none of these.  They are mostly needed when creating a completely new
readtable from scratch.

\section{Functions}
\label{subsec:functions}

Here be dragons.

\section{Stream Types}
\label{sec:stream-types}



% \chapter{References}
% \label{sec:references}
% \begin{description}
% \item[{srfi-10}] \url{http://srfi.schemers.org/srfi-10/srfi-10.html}
% \item[{dynamic scope misnomer}] \url{http://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node43.html}
% \end{description}

\pagebreak
\bibliographystyle{abbrvdin}
\bibliography{references}

\end{document}
